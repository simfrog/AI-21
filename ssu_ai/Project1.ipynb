{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reasonable-static",
   "metadata": {},
   "source": [
    "### 데이터 및 유틸리티 함수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forty-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bored-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: y 데이터 이진 라벨로 변환\n",
    "y = (digits.target == 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-bleeding",
   "metadata": {},
   "source": [
    "### Train / Test 데이터 나누기\n",
    "- test_size=0.2\n",
    "- random_state=0\n",
    "- 클래스가 1 이면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "pacific-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "described-locking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1437, 64)\n",
      "X_test: (360, 64)\n",
      "y_train: (1437,)\n",
      "y_test: (360,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: {}\".format(X_train.shape))\n",
    "print(\"X_test: {}\".format(X_test.shape))\n",
    "print(\"y_train: {}\".format(y_train.shape))\n",
    "print(\"y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-encoding",
   "metadata": {},
   "source": [
    "### 모델 학습 및 평가\n",
    " - 대상 모델: 랜덤 포레스트(sklearn,ensemble,RandomForestClassifier, random_state=0), 로지스틱 회귀(LogisticRegression)\n",
    " - 평가 기준: 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "numerical-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Train 정확도:1.0000\n",
      "RandomForestClassifier Test 정확도:0.9972\n",
      "DecisionTree Train 정확도:1.0000\n",
      "DecisionTree Test 정확도:0.9694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "\n",
    "# TODO: 랜덤 포레스트, 로지스틱 회귀 모델 학습\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train , y_train)\n",
    "rf_acc_train = accuracy_score(y_train, rf_clf.predict(X_train))\n",
    "rf_acc_test = accuracy_score(y_test, rf_clf.predict(X_test))\n",
    "print('RandomForestClassifier Train 정확도:{0:.4f}'.format(rf_acc_train))\n",
    "print('RandomForestClassifier Test 정확도:{0:.4f}'.format(rf_acc_test))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "dt_clf.fit(X_train , y_train)\n",
    "dt_acc_train = accuracy_score(y_train, dt_clf.predict(X_train))\n",
    "dt_acc_test = accuracy_score(y_test, dt_clf.predict(X_test))\n",
    "print('DecisionTree Train 정확도:{0:.4f}'.format(dt_acc_train))\n",
    "print('DecisionTree Test 정확도:{0:.4f}'.format(dt_acc_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-thong",
   "metadata": {},
   "source": [
    "### DecisionTree 하이퍼파라미터 최적화\n",
    " - Target: max_depth (2, 3, 4, 5), min_samples_split (2, 4, 6, 8, 10)\n",
    " - 5-fold cross validation\n",
    " - 최적화 기준: 정확도, 정밀도, 재현율, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "irish-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "latest-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 기준 DecisionTree 최적 하이퍼 파라미터 : {'max_depth': 4, 'min_samples_split': 2}\n",
      "Accuracy 기준 DecisionTree 최고 성능: 0.9701\n",
      "Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : 0.9611\n",
      "Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : 0.7895\n",
      "Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : 0.8333\n",
      "Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 F1 : 0.8108\n"
     ]
    }
   ],
   "source": [
    "# TODO: DecisionTree, Accuracy 기준 최적화\n",
    "dt_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "grid_dt_accuracy = GridSearchCV(dt_clf , param_grid=dt_parameters , scoring='accuracy' , cv=5)\n",
    "grid_dt_accuracy.fit(X_train , y_train)\n",
    "\n",
    "print('Accuracy 기준 DecisionTree 최적 하이퍼 파라미터 :',grid_dt_accuracy.best_params_)\n",
    "print('Accuracy 기준 DecisionTree 최고 성능: {0:.4f}'.format(grid_dt_accuracy.best_score_))\n",
    "best_dt_accuracy = grid_dt_accuracy.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_dt_accuracy_perfacc = accuracy_score(y_test, best_dt_accuracy.predict(X_test))\n",
    "best_dt_accuracy_perfprec = precision_score(y_test, best_dt_accuracy.predict(X_test))\n",
    "best_dt_accuracy_perfrec = recall_score(y_test, best_dt_accuracy.predict(X_test))\n",
    "best_dt_accuracy_perff1 = f1_score(y_test, best_dt_accuracy.predict(X_test))\n",
    "\n",
    "print('Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_dt_accuracy_perfacc))\n",
    "print('Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_dt_accuracy_perfprec))\n",
    "print('Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_dt_accuracy_perfrec))\n",
    "print('Accuracy 기준 DecisionTree 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_dt_accuracy_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "structural-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 기준 DecisionTree 최적 하이퍼 파라미터 : {'max_depth': 5, 'min_samples_split': 10}\n",
      "Precision 기준 DecisionTree 최고 성능: 0.8705\n",
      "Precision 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : 0.9639\n",
      "Precision 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : 0.7949\n",
      "Precision 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : 0.8611\n",
      "Precision 기준 DecisionTree 최적 모델의 테스트 세트 F1 : 0.8267\n"
     ]
    }
   ],
   "source": [
    "# TODO: DecisionTree, Precision 기준 최적화\n",
    "dt_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "grid_dt_precision = GridSearchCV(dt_clf , param_grid=dt_parameters , scoring='precision' , cv=5)\n",
    "grid_dt_precision.fit(X_train , y_train)\n",
    "\n",
    "print('Precision 기준 DecisionTree 최적 하이퍼 파라미터 :',grid_dt_precision.best_params_)\n",
    "print('Precision 기준 DecisionTree 최고 성능: {0:.4f}'.format(grid_dt_precision.best_score_))\n",
    "best_dt_precision = grid_dt_precision.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_dt_precision_perfacc = accuracy_score(y_test, best_dt_precision.predict(X_test))\n",
    "best_dt_precision_perfprec = precision_score(y_test, best_dt_precision.predict(X_test))\n",
    "best_dt_precision_perfrec = recall_score(y_test, best_dt_precision.predict(X_test))\n",
    "best_dt_precision_perff1 = f1_score(y_test, best_dt_precision.predict(X_test))\n",
    "\n",
    "print('Precision 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_dt_precision_perfacc))\n",
    "print('Precision 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_dt_precision_perfprec))\n",
    "print('Precision 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_dt_precision_perfrec))\n",
    "print('Precision 기준 DecisionTree 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_dt_precision_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "spanish-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 기준 DecisionTree 최적 하이퍼 파라미터 : {'max_depth': 5, 'min_samples_split': 2}\n",
      "Recall 기준 DecisionTree 최고 성능: 0.8497\n",
      "Recall 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : 0.9750\n",
      "Recall 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : 0.8857\n",
      "Recall 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : 0.8611\n",
      "Recall 기준 DecisionTree 최적 모델의 테스트 세트 F1 : 0.8732\n"
     ]
    }
   ],
   "source": [
    "# TODO: DecisionTree, Recall 기준 최적화\n",
    "dt_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "grid_dt_recall = GridSearchCV(dt_clf , param_grid=dt_parameters , scoring='recall' , cv=5)\n",
    "grid_dt_recall.fit(X_train , y_train)\n",
    "\n",
    "print('Recall 기준 DecisionTree 최적 하이퍼 파라미터 :',grid_dt_recall.best_params_)\n",
    "print('Recall 기준 DecisionTree 최고 성능: {0:.4f}'.format(grid_dt_recall.best_score_))\n",
    "best_dt_recall = grid_dt_recall.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_dt_recall_perfacc = accuracy_score(y_test, best_dt_recall.predict(X_test))\n",
    "best_dt_recall_perfprec = precision_score(y_test, best_dt_recall.predict(X_test))\n",
    "best_dt_recall_perfrec = recall_score(y_test, best_dt_recall.predict(X_test))\n",
    "best_dt_recall_perff1 = f1_score(y_test, best_dt_recall.predict(X_test))\n",
    "\n",
    "print('Recall 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_dt_recall_perfacc))\n",
    "print('Recall 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_dt_recall_perfprec))\n",
    "print('Recall 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_dt_recall_perfrec))\n",
    "print('Recall 기준 DecisionTree 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_dt_recall_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "subjective-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 기준 DecisionTree 최적 하이퍼 파라미터 : {'max_depth': 4, 'min_samples_split': 2}\n",
      "F1 기준 DecisionTree 최고 성능: 0.8532\n",
      "F1 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : 0.9611\n",
      "F1 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : 0.7895\n",
      "F1 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : 0.8333\n",
      "F1 기준 DecisionTree 최적 모델의 테스트 세트 F1 : 0.8108\n"
     ]
    }
   ],
   "source": [
    "# TODO: DecisionTree, F1 기준 최적화\n",
    "dt_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "grid_dt_f1 = GridSearchCV(dt_clf , param_grid=dt_parameters , scoring='f1' , cv=5)\n",
    "grid_dt_f1.fit(X_train , y_train)\n",
    "\n",
    "print('F1 기준 DecisionTree 최적 하이퍼 파라미터 :',grid_dt_f1.best_params_)\n",
    "print('F1 기준 DecisionTree 최고 성능: {0:.4f}'.format(grid_dt_f1.best_score_))\n",
    "best_dt_f1 = grid_dt_f1.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_dt_f1_perfacc = accuracy_score(y_test, best_dt_f1.predict(X_test))\n",
    "best_dt_f1_perfprec = precision_score(y_test, best_dt_f1.predict(X_test))\n",
    "best_dt_f1_perfrec = recall_score(y_test, best_dt_f1.predict(X_test))\n",
    "best_dt_f1_perff1 = f1_score(y_test, best_dt_f1.predict(X_test))\n",
    "\n",
    "print('F1 기준 DecisionTree 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_dt_f1_perfacc))\n",
    "print('F1 기준 DecisionTree 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_dt_f1_perfprec))\n",
    "print('F1 기준 DecisionTree 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_dt_f1_perfrec))\n",
    "print('F1 기준 DecisionTree 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_dt_f1_perff1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-biotechnology",
   "metadata": {},
   "source": [
    "### RandomForest 하이퍼파라미터 최적화\n",
    " - Target: min_samples_split (2, 4, 6, 8, 10), n_estimators(100, 300, 500)\n",
    " - 5-fold cross validation\n",
    " - 최적화 기준: 정확도, 정밀도, 재현율, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fiscal-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mighty-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 기준 RandomForest 최적 하이퍼 파라미터 : {'min_samples_split': 4, 'n_estimators': 100}\n",
      "Accuracy 기준 RandomForest 최고 성능: 0.9958\n",
      "Accuracy 기준 RandomForest 최적 모델의 테스트 세트 정확도 : 0.9972\n",
      "Accuracy 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : 1.0000\n",
      "Accuracy 기준 RandomForest 최적 모델의 테스트 세트 재현율 : 0.9722\n",
      "Accuracy 기준 RandomForest 최적 모델의 테스트 세트 F1 : 0.9859\n"
     ]
    }
   ],
   "source": [
    "rf_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'n_estimators':[100, 300, 500]}\n",
    "\n",
    "grid_rf_accuracy = GridSearchCV(rf_clf , param_grid=rf_parameters , scoring='accuracy' , cv=5)\n",
    "grid_rf_accuracy.fit(X_train , y_train)\n",
    "\n",
    "print('Accuracy 기준 RandomForest 최적 하이퍼 파라미터 :',grid_rf_accuracy.best_params_)\n",
    "print('Accuracy 기준 RandomForest 최고 성능: {0:.4f}'.format(grid_rf_accuracy.best_score_))\n",
    "best_rf_accuracy = grid_rf_accuracy.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_rf_accuracy_perfacc = accuracy_score(y_test, best_rf_accuracy.predict(X_test))\n",
    "best_rf_accuracy_perfprec = precision_score(y_test, best_rf_accuracy.predict(X_test))\n",
    "best_rf_accuracy_perfrec = recall_score(y_test, best_rf_accuracy.predict(X_test))\n",
    "best_rf_accuracy_perff1 = f1_score(y_test, best_rf_accuracy.predict(X_test))\n",
    "\n",
    "print('Accuracy 기준 RandomForest 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_rf_accuracy_perfacc))\n",
    "print('Accuracy 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_rf_accuracy_perfprec))\n",
    "print('Accuracy 기준 RandomForest 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_rf_accuracy_perfrec))\n",
    "print('Accuracy 기준 RandomForest 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_rf_accuracy_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "detailed-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 기준 RandomForest 최적 하이퍼 파라미터 : {'min_samples_split': 4, 'n_estimators': 100}\n",
      "Precision 기준 RandomForest 최고 성능: 1.0000\n",
      "Precision 기준 RandomForest 최적 모델의 테스트 세트 정확도 : 0.9972\n",
      "Precision 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : 1.0000\n",
      "Precision 기준 RandomForest 최적 모델의 테스트 세트 재현율 : 0.9722\n",
      "Precision 기준 RandomForest 최적 모델의 테스트 세트 F1 : 0.9722\n"
     ]
    }
   ],
   "source": [
    "# TODO: RandomFrest, Precision 기준 최적화\n",
    "\n",
    "rf_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'n_estimators':[100, 300, 500]}\n",
    "\n",
    "grid_rf_prec = GridSearchCV(rf_clf , param_grid=rf_parameters , scoring='precision' , cv=5)\n",
    "grid_rf_prec.fit(X_train , y_train)\n",
    "\n",
    "print('Precision 기준 RandomForest 최적 하이퍼 파라미터 :',grid_rf_prec.best_params_)\n",
    "print('Precision 기준 RandomForest 최고 성능: {0:.4f}'.format(grid_rf_prec.best_score_))\n",
    "best_rf_prec = grid_rf_prec.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_rf_prec_perfacc = accuracy_score(y_test, best_rf_prec.predict(X_test))\n",
    "best_rf_prec_perfprec = precision_score(y_test, best_rf_prec.predict(X_test))\n",
    "best_rf_prec_perfrec = recall_score(y_test, best_rf_prec.predict(X_test))\n",
    "best_rf_prec_perff1 = recall_score(y_test, best_rf_prec.predict(X_test))\n",
    "\n",
    "print('Precision 기준 RandomForest 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_rf_prec_perfacc))\n",
    "print('Precision 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_rf_prec_perfprec))\n",
    "print('Precision 기준 RandomForest 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_rf_prec_perfrec))\n",
    "print('Precision 기준 RandomForest 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_rf_prec_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "coastal-issue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 기준 RandomForest 최적 하이퍼 파라미터 : {'min_samples_split': 2, 'n_estimators': 300}\n",
      "Recall 기준 RandomForest 최고 성능: 0.9591\n",
      "Recall 기준 RandomForest 최적 모델의 테스트 세트 정확도 : 0.9944\n",
      "Recall 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : 1.0000\n",
      "Recall 기준 RandomForest 최적 모델의 테스트 세트 재현율 : 0.9444\n",
      "Recall 기준 RandomForest 최적 모델의 테스트 세트 F1 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "# TODO: RandomForest, Recall 기준 최적화\n",
    "\n",
    "rf_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'n_estimators':[100, 300, 500]}\n",
    "\n",
    "grid_rf_rec = GridSearchCV(rf_clf , param_grid=rf_parameters , scoring='recall' , cv=5)\n",
    "grid_rf_rec.fit(X_train , y_train)\n",
    "\n",
    "print('Recall 기준 RandomForest 최적 하이퍼 파라미터 :',grid_rf_rec.best_params_)\n",
    "print('Recall 기준 RandomForest 최고 성능: {0:.4f}'.format(grid_rf_rec.best_score_))\n",
    "best_rf_rec = grid_rf_rec.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_rf_rec_perfacc = accuracy_score(y_test, best_rf_rec.predict(X_test))\n",
    "best_rf_rec_perfprec = precision_score(y_test, best_rf_rec.predict(X_test))\n",
    "best_rf_rec_perfrec = recall_score(y_test, best_rf_rec.predict(X_test))\n",
    "best_rf_rec_perff1 = f1_score(y_test, best_rf_rec.predict(X_test))\n",
    "\n",
    "print('Recall 기준 RandomForest 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_rf_rec_perfacc))\n",
    "print('Recall 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_rf_rec_perfprec))\n",
    "print('Recall 기준 RandomForest 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_rf_rec_perfrec))\n",
    "print('Recall 기준 RandomForest 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_rf_rec_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "radical-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 기준 RandomForest 최적 하이퍼 파라미터 : {'min_samples_split': 2, 'n_estimators': 300}\n",
      "Recall 기준 RandomForest 최고 성능: 0.9591\n",
      "F1 기준 RandomForest 최적 모델의 테스트 세트 정확도 : 0.9972\n",
      "F1 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : 1.0000\n",
      "F1 기준 RandomForest 최적 모델의 테스트 세트 재현율 : 0.9722\n",
      "F1 기준 RandomForest 최적 모델의 테스트 세트 F1 : 0.9859\n"
     ]
    }
   ],
   "source": [
    "# TODO: RandomForest, F1 기준 최적화\n",
    "\n",
    "rf_parameters = {'min_samples_split':[2, 4, 6, 8, 10], 'n_estimators':[100, 300, 500]}\n",
    "\n",
    "grid_rf_f1 = GridSearchCV(rf_clf , param_grid=rf_parameters , scoring='f1' , cv=5)\n",
    "grid_rf_f1.fit(X_train , y_train)\n",
    "\n",
    "print('Recall 기준 RandomForest 최적 하이퍼 파라미터 :',grid_rf_rec.best_params_)\n",
    "print('Recall 기준 RandomForest 최고 성능: {0:.4f}'.format(grid_rf_rec.best_score_))\n",
    "best_rf_f1 = grid_rf_f1.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "best_rf_f1_perfacc = accuracy_score(y_test, best_rf_f1.predict(X_test))\n",
    "best_rf_f1_perfprec = precision_score(y_test, best_rf_f1.predict(X_test))\n",
    "best_rf_f1_perfrec = recall_score(y_test, best_rf_f1.predict(X_test))\n",
    "best_rf_f1_perff1 = f1_score(y_test, best_rf_f1.predict(X_test))\n",
    "\n",
    "print('F1 기준 RandomForest 최적 모델의 테스트 세트 정확도 : {0:.4f}'.format(best_rf_f1_perfacc))\n",
    "print('F1 기준 RandomForest 최적 모델의 테스트 세트 정밀도 : {0:.4f}'.format(best_rf_f1_perfprec))\n",
    "print('F1 기준 RandomForest 최적 모델의 테스트 세트 재현율 : {0:.4f}'.format(best_rf_f1_perfrec))\n",
    "print('F1 기준 RandomForest 최적 모델의 테스트 세트 F1 : {0:.4f}'.format(best_rf_f1_perff1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-tucson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ssu] *",
   "language": "python",
   "name": "conda-env-ssu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
