{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2b7801",
   "metadata": {},
   "source": [
    "# test_df 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df6d66",
   "metadata": {},
   "source": [
    "test data 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6935d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9107 entries, 0 to 9106\n",
      "Data columns (total 77 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   index       9107 non-null   int64  \n",
      " 1   QaA         9107 non-null   float64\n",
      " 2   QaE         9107 non-null   int64  \n",
      " 3   QbA         9107 non-null   float64\n",
      " 4   QbE         9107 non-null   int64  \n",
      " 5   QcA         9107 non-null   float64\n",
      " 6   QcE         9107 non-null   int64  \n",
      " 7   QdA         9107 non-null   float64\n",
      " 8   QdE         9107 non-null   int64  \n",
      " 9   QeA         9107 non-null   float64\n",
      " 10  QeE         9107 non-null   int64  \n",
      " 11  QfA         9107 non-null   float64\n",
      " 12  QfE         9107 non-null   int64  \n",
      " 13  QgA         9107 non-null   float64\n",
      " 14  QgE         9107 non-null   int64  \n",
      " 15  QhA         9107 non-null   float64\n",
      " 16  QhE         9107 non-null   int64  \n",
      " 17  QiA         9107 non-null   float64\n",
      " 18  QiE         9107 non-null   int64  \n",
      " 19  QjA         9107 non-null   float64\n",
      " 20  QjE         9107 non-null   int64  \n",
      " 21  QkA         9107 non-null   float64\n",
      " 22  QkE         9107 non-null   int64  \n",
      " 23  QlA         9107 non-null   float64\n",
      " 24  QlE         9107 non-null   int64  \n",
      " 25  QmA         9107 non-null   float64\n",
      " 26  QmE         9107 non-null   int64  \n",
      " 27  QnA         9107 non-null   float64\n",
      " 28  QnE         9107 non-null   int64  \n",
      " 29  QoA         9107 non-null   float64\n",
      " 30  QoE         9107 non-null   int64  \n",
      " 31  QpA         9107 non-null   float64\n",
      " 32  QpE         9107 non-null   int64  \n",
      " 33  QqA         9107 non-null   float64\n",
      " 34  QqE         9107 non-null   int64  \n",
      " 35  QrA         9107 non-null   float64\n",
      " 36  QrE         9107 non-null   int64  \n",
      " 37  QsA         9107 non-null   float64\n",
      " 38  QsE         9107 non-null   int64  \n",
      " 39  QtA         9107 non-null   float64\n",
      " 40  QtE         9107 non-null   int64  \n",
      " 41  age_group   9107 non-null   object \n",
      " 42  education   9107 non-null   int64  \n",
      " 43  engnat      9107 non-null   int64  \n",
      " 44  familysize  9107 non-null   int64  \n",
      " 45  gender      9107 non-null   object \n",
      " 46  hand        9107 non-null   int64  \n",
      " 47  married     9107 non-null   int64  \n",
      " 48  race        9107 non-null   object \n",
      " 49  religion    9107 non-null   object \n",
      " 50  tp01        9107 non-null   int64  \n",
      " 51  tp02        9107 non-null   int64  \n",
      " 52  tp03        9107 non-null   int64  \n",
      " 53  tp04        9107 non-null   int64  \n",
      " 54  tp05        9107 non-null   int64  \n",
      " 55  tp06        9107 non-null   int64  \n",
      " 56  tp07        9107 non-null   int64  \n",
      " 57  tp08        9107 non-null   int64  \n",
      " 58  tp09        9107 non-null   int64  \n",
      " 59  tp10        9107 non-null   int64  \n",
      " 60  urban       9107 non-null   int64  \n",
      " 61  wf_01       9107 non-null   int64  \n",
      " 62  wf_02       9107 non-null   int64  \n",
      " 63  wf_03       9107 non-null   int64  \n",
      " 64  wr_01       9107 non-null   int64  \n",
      " 65  wr_02       9107 non-null   int64  \n",
      " 66  wr_03       9107 non-null   int64  \n",
      " 67  wr_04       9107 non-null   int64  \n",
      " 68  wr_05       9107 non-null   int64  \n",
      " 69  wr_06       9107 non-null   int64  \n",
      " 70  wr_07       9107 non-null   int64  \n",
      " 71  wr_08       9107 non-null   int64  \n",
      " 72  wr_09       9107 non-null   int64  \n",
      " 73  wr_10       9107 non-null   int64  \n",
      " 74  wr_11       9107 non-null   int64  \n",
      " 75  wr_12       9107 non-null   int64  \n",
      " 76  wr_13       9107 non-null   int64  \n",
      "dtypes: float64(20), int64(53), object(4)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_raw = pd.read_csv(\"test.csv\")\n",
    "test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8c4ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9107 entries, 0 to 9106\n",
      "Data columns (total 77 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   index       9107 non-null   int64  \n",
      " 1   QaA         9107 non-null   float64\n",
      " 2   QaE         9107 non-null   int64  \n",
      " 3   QbA         9107 non-null   float64\n",
      " 4   QbE         9107 non-null   int64  \n",
      " 5   QcA         9107 non-null   float64\n",
      " 6   QcE         9107 non-null   int64  \n",
      " 7   QdA         9107 non-null   float64\n",
      " 8   QdE         9107 non-null   int64  \n",
      " 9   QeA         9107 non-null   float64\n",
      " 10  QeE         9107 non-null   int64  \n",
      " 11  QfA         9107 non-null   float64\n",
      " 12  QfE         9107 non-null   int64  \n",
      " 13  QgA         9107 non-null   float64\n",
      " 14  QgE         9107 non-null   int64  \n",
      " 15  QhA         9107 non-null   float64\n",
      " 16  QhE         9107 non-null   int64  \n",
      " 17  QiA         9107 non-null   float64\n",
      " 18  QiE         9107 non-null   int64  \n",
      " 19  QjA         9107 non-null   float64\n",
      " 20  QjE         9107 non-null   int64  \n",
      " 21  QkA         9107 non-null   float64\n",
      " 22  QkE         9107 non-null   int64  \n",
      " 23  QlA         9107 non-null   float64\n",
      " 24  QlE         9107 non-null   int64  \n",
      " 25  QmA         9107 non-null   float64\n",
      " 26  QmE         9107 non-null   int64  \n",
      " 27  QnA         9107 non-null   float64\n",
      " 28  QnE         9107 non-null   int64  \n",
      " 29  QoA         9107 non-null   float64\n",
      " 30  QoE         9107 non-null   int64  \n",
      " 31  QpA         9107 non-null   float64\n",
      " 32  QpE         9107 non-null   int64  \n",
      " 33  QqA         9107 non-null   float64\n",
      " 34  QqE         9107 non-null   int64  \n",
      " 35  QrA         9107 non-null   float64\n",
      " 36  QrE         9107 non-null   int64  \n",
      " 37  QsA         9107 non-null   float64\n",
      " 38  QsE         9107 non-null   int64  \n",
      " 39  QtA         9107 non-null   float64\n",
      " 40  QtE         9107 non-null   int64  \n",
      " 41  age_group   9107 non-null   object \n",
      " 42  education   9107 non-null   int64  \n",
      " 43  engnat      9107 non-null   int64  \n",
      " 44  familysize  9107 non-null   int64  \n",
      " 45  gender      9107 non-null   object \n",
      " 46  hand        9107 non-null   int64  \n",
      " 47  married     9107 non-null   int64  \n",
      " 48  race        9107 non-null   object \n",
      " 49  religion    9107 non-null   object \n",
      " 50  tp01        9107 non-null   int64  \n",
      " 51  tp02        9107 non-null   int64  \n",
      " 52  tp03        9107 non-null   int64  \n",
      " 53  tp04        9107 non-null   int64  \n",
      " 54  tp05        9107 non-null   int64  \n",
      " 55  tp06        9107 non-null   int64  \n",
      " 56  tp07        9107 non-null   int64  \n",
      " 57  tp08        9107 non-null   int64  \n",
      " 58  tp09        9107 non-null   int64  \n",
      " 59  tp10        9107 non-null   int64  \n",
      " 60  urban       9107 non-null   int64  \n",
      " 61  wf_01       9107 non-null   int64  \n",
      " 62  wf_02       9107 non-null   int64  \n",
      " 63  wf_03       9107 non-null   int64  \n",
      " 64  wr_01       9107 non-null   int64  \n",
      " 65  wr_02       9107 non-null   int64  \n",
      " 66  wr_03       9107 non-null   int64  \n",
      " 67  wr_04       9107 non-null   int64  \n",
      " 68  wr_05       9107 non-null   int64  \n",
      " 69  wr_06       9107 non-null   int64  \n",
      " 70  wr_07       9107 non-null   int64  \n",
      " 71  wr_08       9107 non-null   int64  \n",
      " 72  wr_09       9107 non-null   int64  \n",
      " 73  wr_10       9107 non-null   int64  \n",
      " 74  wr_11       9107 non-null   int64  \n",
      " 75  wr_12       9107 non-null   int64  \n",
      " 76  wr_13       9107 non-null   int64  \n",
      "dtypes: float64(20), int64(53), object(4)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df = test_raw\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7cd00",
   "metadata": {},
   "source": [
    "'gender' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3345ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9102    1\n",
       "9103    1\n",
       "9104    1\n",
       "9105    1\n",
       "9106    1\n",
       "Name: gender, Length: 9107, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = test_df['gender']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "gender_pre = encoder.transform(items)\n",
    "\n",
    "test_df['gender']= gender_pre \n",
    "test_df['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113dea2",
   "metadata": {},
   "source": [
    "'age_group' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0183e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_group에서 \"s\" , \"+\" 제거\n",
    "test_df['age_group'] = test_df['age_group'].str.strip(\"s\")\n",
    "test_df['age_group'] = test_df['age_group'].str.strip(\"+\")\n",
    "# 문자열 -> 정수 변환\n",
    "test_df['age_group'] = pd.to_numeric(test_df['age_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9faceec",
   "metadata": {},
   "source": [
    "'race' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63abe821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "      <th>race_Arab</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Indigenous Australian</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3768</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1027</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351</td>\n",
       "      <td>2.0</td>\n",
       "      <td>761</td>\n",
       "      <td>3.0</td>\n",
       "      <td>474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>569</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>461</td>\n",
       "      <td>3.0</td>\n",
       "      <td>567</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>805</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2828</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>28225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347</td>\n",
       "      <td>5.0</td>\n",
       "      <td>755</td>\n",
       "      <td>5.0</td>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>5610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>370</td>\n",
       "      <td>4.0</td>\n",
       "      <td>694</td>\n",
       "      <td>5.0</td>\n",
       "      <td>564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>41745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>843</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3181</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>24818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1346</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>33355</td>\n",
       "      <td>4.0</td>\n",
       "      <td>606</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  wr_11  \\\n",
       "0     38741  1.0  1069  4.0  3768  5.0   953  2.0  1027  5.0  ...      0   \n",
       "1     43904  2.0   351  2.0   761  3.0   474  2.0   569  2.0  ...      1   \n",
       "2     41036  2.0   469  1.0  5394  1.0   461  3.0   567  4.0  ...      0   \n",
       "3      6939  2.0   805  5.0  2828  2.0  2503  1.0  2332  1.0  ...      1   \n",
       "4     14682  1.0   541  4.0   700  4.0  1110  1.0   398  1.0  ...      0   \n",
       "...     ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...    ...   \n",
       "9102  28225  1.0   347  5.0   755  5.0   888  1.0   775  1.0  ...      0   \n",
       "9103   5610  1.0   370  4.0   694  5.0   564  1.0   665  1.0  ...      0   \n",
       "9104  41745  1.0   843  3.0  3181  5.0   113  1.0  1280  4.0  ...      0   \n",
       "9105  24818  3.0  1346  3.0  1532  5.0  1245  1.0  1033  1.0  ...      0   \n",
       "9106  33355  4.0   606  4.0  2084  4.0  2297  4.0  2107  4.0  ...      0   \n",
       "\n",
       "      wr_12  wr_13  race_Arab  race_Asian  race_Black  \\\n",
       "0         1      1          0           0           0   \n",
       "1         1      1          0           0           0   \n",
       "2         1      1          0           0           0   \n",
       "3         1      1          0           0           0   \n",
       "4         1      1          0           0           0   \n",
       "...     ...    ...        ...         ...         ...   \n",
       "9102      1      0          0           0           0   \n",
       "9103      1      1          0           0           0   \n",
       "9104      1      1          0           1           0   \n",
       "9105      1      1          0           1           0   \n",
       "9106      1      1          0           0           0   \n",
       "\n",
       "      race_Indigenous Australian  race_Native American  race_Other  race_White  \n",
       "0                              0                     0           0           1  \n",
       "1                              0                     0           0           1  \n",
       "2                              0                     0           0           1  \n",
       "3                              0                     0           0           1  \n",
       "4                              0                     0           0           1  \n",
       "...                          ...                   ...         ...         ...  \n",
       "9102                           0                     0           0           1  \n",
       "9103                           0                     0           0           1  \n",
       "9104                           0                     0           0           0  \n",
       "9105                           0                     0           0           0  \n",
       "9106                           0                     0           1           0  \n",
       "\n",
       "[9107 rows x 84 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_race = test_df['race']\n",
    "\n",
    "df = pd.DataFrame({'race':vote_race})\n",
    "race_onehot = pd.get_dummies(df)\n",
    "\n",
    "# 데이터 프레임에 추가\n",
    "test_df['race_Arab']= race_onehot['race_Arab']\n",
    "test_df['race_Asian']= race_onehot['race_Asian']\n",
    "test_df['race_Black']= race_onehot['race_Black']\n",
    "test_df['race_Indigenous Australian']= race_onehot['race_Indigenous Australian']\n",
    "test_df['race_Native American']= race_onehot['race_Native American']\n",
    "test_df['race_Other']= race_onehot['race_Other']\n",
    "test_df['race_White']= race_onehot['race_White']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4f234",
   "metadata": {},
   "source": [
    "'religion' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17026e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>religion_Buddhist</th>\n",
       "      <th>religion_Christian_Catholic</th>\n",
       "      <th>religion_Christian_Mormon</th>\n",
       "      <th>religion_Christian_Protestant</th>\n",
       "      <th>religion_Christian_Other</th>\n",
       "      <th>religion_Hindu</th>\n",
       "      <th>religion_Jewish</th>\n",
       "      <th>religion_Muslim</th>\n",
       "      <th>religion_Sikh</th>\n",
       "      <th>religion_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3768</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1027</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351</td>\n",
       "      <td>2.0</td>\n",
       "      <td>761</td>\n",
       "      <td>3.0</td>\n",
       "      <td>474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>569</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41036</td>\n",
       "      <td>2.0</td>\n",
       "      <td>469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>461</td>\n",
       "      <td>3.0</td>\n",
       "      <td>567</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>805</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2828</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>28225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347</td>\n",
       "      <td>5.0</td>\n",
       "      <td>755</td>\n",
       "      <td>5.0</td>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>5610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>370</td>\n",
       "      <td>4.0</td>\n",
       "      <td>694</td>\n",
       "      <td>5.0</td>\n",
       "      <td>564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>41745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>843</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3181</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>24818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1346</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>33355</td>\n",
       "      <td>4.0</td>\n",
       "      <td>606</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  \\\n",
       "0     38741  1.0  1069  4.0  3768  5.0   953  2.0  1027  5.0  ...   \n",
       "1     43904  2.0   351  2.0   761  3.0   474  2.0   569  2.0  ...   \n",
       "2     41036  2.0   469  1.0  5394  1.0   461  3.0   567  4.0  ...   \n",
       "3      6939  2.0   805  5.0  2828  2.0  2503  1.0  2332  1.0  ...   \n",
       "4     14682  1.0   541  4.0   700  4.0  1110  1.0   398  1.0  ...   \n",
       "...     ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...   \n",
       "9102  28225  1.0   347  5.0   755  5.0   888  1.0   775  1.0  ...   \n",
       "9103   5610  1.0   370  4.0   694  5.0   564  1.0   665  1.0  ...   \n",
       "9104  41745  1.0   843  3.0  3181  5.0   113  1.0  1280  4.0  ...   \n",
       "9105  24818  3.0  1346  3.0  1532  5.0  1245  1.0  1033  1.0  ...   \n",
       "9106  33355  4.0   606  4.0  2084  4.0  2297  4.0  2107  4.0  ...   \n",
       "\n",
       "      religion_Buddhist  religion_Christian_Catholic  \\\n",
       "0                     0                            0   \n",
       "1                     0                            0   \n",
       "2                     0                            0   \n",
       "3                     0                            0   \n",
       "4                     0                            0   \n",
       "...                 ...                          ...   \n",
       "9102                  1                            0   \n",
       "9103                  0                            0   \n",
       "9104                  0                            0   \n",
       "9105                  0                            0   \n",
       "9106                  0                            0   \n",
       "\n",
       "      religion_Christian_Mormon  religion_Christian_Protestant  \\\n",
       "0                             0                              0   \n",
       "1                             0                              1   \n",
       "2                             0                              0   \n",
       "3                             0                              0   \n",
       "4                             0                              0   \n",
       "...                         ...                            ...   \n",
       "9102                          0                              0   \n",
       "9103                          0                              1   \n",
       "9104                          0                              0   \n",
       "9105                          0                              0   \n",
       "9106                          0                              0   \n",
       "\n",
       "      religion_Christian_Other  religion_Hindu  religion_Jewish  \\\n",
       "0                            0               0                0   \n",
       "1                            0               0                0   \n",
       "2                            0               0                0   \n",
       "3                            0               0                0   \n",
       "4                            0               0                0   \n",
       "...                        ...             ...              ...   \n",
       "9102                         0               0                0   \n",
       "9103                         0               0                0   \n",
       "9104                         0               1                0   \n",
       "9105                         0               1                0   \n",
       "9106                         1               0                0   \n",
       "\n",
       "      religion_Muslim  religion_Sikh  religion_Other  \n",
       "0                   0              0               0  \n",
       "1                   0              0               0  \n",
       "2                   0              0               0  \n",
       "3                   0              0               0  \n",
       "4                   0              0               0  \n",
       "...               ...            ...             ...  \n",
       "9102                0              0               0  \n",
       "9103                0              0               0  \n",
       "9104                0              0               0  \n",
       "9105                0              0               0  \n",
       "9106                0              0               0  \n",
       "\n",
       "[9107 rows x 96 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# religion\n",
    "vote_religion = test_df['religion']\n",
    "\n",
    "df = pd.DataFrame({'religion':vote_religion})\n",
    "religion_onehot = pd.get_dummies(df)\n",
    "\n",
    "# 데이터 프레임에 추가\n",
    "test_df['religion_Agnostic']= religion_onehot['religion_Agnostic']\n",
    "test_df['religion_Atheist']= religion_onehot['religion_Atheist']\n",
    "test_df['religion_Buddhist']= religion_onehot['religion_Buddhist']\n",
    "test_df['religion_Christian_Catholic']= religion_onehot['religion_Christian_Catholic']\n",
    "test_df['religion_Christian_Mormon']= religion_onehot['religion_Christian_Mormon']\n",
    "test_df['religion_Christian_Protestant']= religion_onehot['religion_Christian_Protestant']\n",
    "test_df['religion_Christian_Other']= religion_onehot['religion_Christian_Other']\n",
    "test_df['religion_Hindu']= religion_onehot['religion_Hindu']\n",
    "test_df['religion_Jewish']= religion_onehot['religion_Jewish']\n",
    "test_df['religion_Muslim']= religion_onehot['religion_Muslim']\n",
    "test_df['religion_Sikh']= religion_onehot['religion_Sikh']\n",
    "test_df['religion_Other']= religion_onehot['religion_Other']\n",
    "\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe80bb1",
   "metadata": {},
   "source": [
    "데이터 타입 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354d9ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9107 entries, 0 to 9106\n",
      "Data columns (total 96 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   index                          9107 non-null   int64 \n",
      " 1   QaA                            9107 non-null   int64 \n",
      " 2   QaE                            9107 non-null   int64 \n",
      " 3   QbA                            9107 non-null   int64 \n",
      " 4   QbE                            9107 non-null   int64 \n",
      " 5   QcA                            9107 non-null   int64 \n",
      " 6   QcE                            9107 non-null   int64 \n",
      " 7   QdA                            9107 non-null   int64 \n",
      " 8   QdE                            9107 non-null   int64 \n",
      " 9   QeA                            9107 non-null   int64 \n",
      " 10  QeE                            9107 non-null   int64 \n",
      " 11  QfA                            9107 non-null   int64 \n",
      " 12  QfE                            9107 non-null   int64 \n",
      " 13  QgA                            9107 non-null   int64 \n",
      " 14  QgE                            9107 non-null   int64 \n",
      " 15  QhA                            9107 non-null   int64 \n",
      " 16  QhE                            9107 non-null   int64 \n",
      " 17  QiA                            9107 non-null   int64 \n",
      " 18  QiE                            9107 non-null   int64 \n",
      " 19  QjA                            9107 non-null   int64 \n",
      " 20  QjE                            9107 non-null   int64 \n",
      " 21  QkA                            9107 non-null   int64 \n",
      " 22  QkE                            9107 non-null   int64 \n",
      " 23  QlA                            9107 non-null   int64 \n",
      " 24  QlE                            9107 non-null   int64 \n",
      " 25  QmA                            9107 non-null   int64 \n",
      " 26  QmE                            9107 non-null   int64 \n",
      " 27  QnA                            9107 non-null   int64 \n",
      " 28  QnE                            9107 non-null   int64 \n",
      " 29  QoA                            9107 non-null   int64 \n",
      " 30  QoE                            9107 non-null   int64 \n",
      " 31  QpA                            9107 non-null   int64 \n",
      " 32  QpE                            9107 non-null   int64 \n",
      " 33  QqA                            9107 non-null   int64 \n",
      " 34  QqE                            9107 non-null   int64 \n",
      " 35  QrA                            9107 non-null   int64 \n",
      " 36  QrE                            9107 non-null   int64 \n",
      " 37  QsA                            9107 non-null   int64 \n",
      " 38  QsE                            9107 non-null   int64 \n",
      " 39  QtA                            9107 non-null   int64 \n",
      " 40  QtE                            9107 non-null   int64 \n",
      " 41  age_group                      9107 non-null   int64 \n",
      " 42  education                      9107 non-null   int64 \n",
      " 43  engnat                         9107 non-null   int64 \n",
      " 44  familysize                     9107 non-null   int64 \n",
      " 45  gender                         9107 non-null   int64 \n",
      " 46  hand                           9107 non-null   int64 \n",
      " 47  married                        9107 non-null   int64 \n",
      " 48  race                           9107 non-null   object\n",
      " 49  religion                       9107 non-null   object\n",
      " 50  tp01                           9107 non-null   int64 \n",
      " 51  tp02                           9107 non-null   int64 \n",
      " 52  tp03                           9107 non-null   int64 \n",
      " 53  tp04                           9107 non-null   int64 \n",
      " 54  tp05                           9107 non-null   int64 \n",
      " 55  tp06                           9107 non-null   int64 \n",
      " 56  tp07                           9107 non-null   int64 \n",
      " 57  tp08                           9107 non-null   int64 \n",
      " 58  tp09                           9107 non-null   int64 \n",
      " 59  tp10                           9107 non-null   int64 \n",
      " 60  urban                          9107 non-null   int64 \n",
      " 61  wf_01                          9107 non-null   int64 \n",
      " 62  wf_02                          9107 non-null   int64 \n",
      " 63  wf_03                          9107 non-null   int64 \n",
      " 64  wr_01                          9107 non-null   int64 \n",
      " 65  wr_02                          9107 non-null   int64 \n",
      " 66  wr_03                          9107 non-null   int64 \n",
      " 67  wr_04                          9107 non-null   int64 \n",
      " 68  wr_05                          9107 non-null   int64 \n",
      " 69  wr_06                          9107 non-null   int64 \n",
      " 70  wr_07                          9107 non-null   int64 \n",
      " 71  wr_08                          9107 non-null   int64 \n",
      " 72  wr_09                          9107 non-null   int64 \n",
      " 73  wr_10                          9107 non-null   int64 \n",
      " 74  wr_11                          9107 non-null   int64 \n",
      " 75  wr_12                          9107 non-null   int64 \n",
      " 76  wr_13                          9107 non-null   int64 \n",
      " 77  race_Arab                      9107 non-null   int64 \n",
      " 78  race_Asian                     9107 non-null   int64 \n",
      " 79  race_Black                     9107 non-null   int64 \n",
      " 80  race_Indigenous Australian     9107 non-null   int64 \n",
      " 81  race_Native American           9107 non-null   int64 \n",
      " 82  race_Other                     9107 non-null   int64 \n",
      " 83  race_White                     9107 non-null   int64 \n",
      " 84  religion_Agnostic              9107 non-null   int64 \n",
      " 85  religion_Atheist               9107 non-null   int64 \n",
      " 86  religion_Buddhist              9107 non-null   int64 \n",
      " 87  religion_Christian_Catholic    9107 non-null   int64 \n",
      " 88  religion_Christian_Mormon      9107 non-null   int64 \n",
      " 89  religion_Christian_Protestant  9107 non-null   int64 \n",
      " 90  religion_Christian_Other       9107 non-null   int64 \n",
      " 91  religion_Hindu                 9107 non-null   int64 \n",
      " 92  religion_Jewish                9107 non-null   int64 \n",
      " 93  religion_Muslim                9107 non-null   int64 \n",
      " 94  religion_Sikh                  9107 non-null   int64 \n",
      " 95  religion_Other                 9107 non-null   int64 \n",
      "dtypes: int64(94), object(2)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "for i in test_df:\n",
    "    if i.find('A') is not -1:\n",
    "        test_df = test_df.astype({i:'int64'})\n",
    "\n",
    "for i in test_df:\n",
    "    if i.find('race_') is not -1:\n",
    "        test_df = test_df.astype({i:'int64'})\n",
    "\n",
    "for i in test_df:\n",
    "    if i.find('religion_') is not -1:\n",
    "        test_df = test_df.astype({i:'int64'})\n",
    "\n",
    "for i in test_df:\n",
    "    if i.find('gender') is not -1:\n",
    "        test_df = test_df.astype({i:'int64'})\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736bf61",
   "metadata": {},
   "source": [
    "'index', 'race', 'religion' 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6fda83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9107 entries, 0 to 9106\n",
      "Data columns (total 93 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   QaA                            9107 non-null   int64\n",
      " 1   QaE                            9107 non-null   int64\n",
      " 2   QbA                            9107 non-null   int64\n",
      " 3   QbE                            9107 non-null   int64\n",
      " 4   QcA                            9107 non-null   int64\n",
      " 5   QcE                            9107 non-null   int64\n",
      " 6   QdA                            9107 non-null   int64\n",
      " 7   QdE                            9107 non-null   int64\n",
      " 8   QeA                            9107 non-null   int64\n",
      " 9   QeE                            9107 non-null   int64\n",
      " 10  QfA                            9107 non-null   int64\n",
      " 11  QfE                            9107 non-null   int64\n",
      " 12  QgA                            9107 non-null   int64\n",
      " 13  QgE                            9107 non-null   int64\n",
      " 14  QhA                            9107 non-null   int64\n",
      " 15  QhE                            9107 non-null   int64\n",
      " 16  QiA                            9107 non-null   int64\n",
      " 17  QiE                            9107 non-null   int64\n",
      " 18  QjA                            9107 non-null   int64\n",
      " 19  QjE                            9107 non-null   int64\n",
      " 20  QkA                            9107 non-null   int64\n",
      " 21  QkE                            9107 non-null   int64\n",
      " 22  QlA                            9107 non-null   int64\n",
      " 23  QlE                            9107 non-null   int64\n",
      " 24  QmA                            9107 non-null   int64\n",
      " 25  QmE                            9107 non-null   int64\n",
      " 26  QnA                            9107 non-null   int64\n",
      " 27  QnE                            9107 non-null   int64\n",
      " 28  QoA                            9107 non-null   int64\n",
      " 29  QoE                            9107 non-null   int64\n",
      " 30  QpA                            9107 non-null   int64\n",
      " 31  QpE                            9107 non-null   int64\n",
      " 32  QqA                            9107 non-null   int64\n",
      " 33  QqE                            9107 non-null   int64\n",
      " 34  QrA                            9107 non-null   int64\n",
      " 35  QrE                            9107 non-null   int64\n",
      " 36  QsA                            9107 non-null   int64\n",
      " 37  QsE                            9107 non-null   int64\n",
      " 38  QtA                            9107 non-null   int64\n",
      " 39  QtE                            9107 non-null   int64\n",
      " 40  age_group                      9107 non-null   int64\n",
      " 41  education                      9107 non-null   int64\n",
      " 42  engnat                         9107 non-null   int64\n",
      " 43  familysize                     9107 non-null   int64\n",
      " 44  gender                         9107 non-null   int64\n",
      " 45  hand                           9107 non-null   int64\n",
      " 46  married                        9107 non-null   int64\n",
      " 47  tp01                           9107 non-null   int64\n",
      " 48  tp02                           9107 non-null   int64\n",
      " 49  tp03                           9107 non-null   int64\n",
      " 50  tp04                           9107 non-null   int64\n",
      " 51  tp05                           9107 non-null   int64\n",
      " 52  tp06                           9107 non-null   int64\n",
      " 53  tp07                           9107 non-null   int64\n",
      " 54  tp08                           9107 non-null   int64\n",
      " 55  tp09                           9107 non-null   int64\n",
      " 56  tp10                           9107 non-null   int64\n",
      " 57  urban                          9107 non-null   int64\n",
      " 58  wf_01                          9107 non-null   int64\n",
      " 59  wf_02                          9107 non-null   int64\n",
      " 60  wf_03                          9107 non-null   int64\n",
      " 61  wr_01                          9107 non-null   int64\n",
      " 62  wr_02                          9107 non-null   int64\n",
      " 63  wr_03                          9107 non-null   int64\n",
      " 64  wr_04                          9107 non-null   int64\n",
      " 65  wr_05                          9107 non-null   int64\n",
      " 66  wr_06                          9107 non-null   int64\n",
      " 67  wr_07                          9107 non-null   int64\n",
      " 68  wr_08                          9107 non-null   int64\n",
      " 69  wr_09                          9107 non-null   int64\n",
      " 70  wr_10                          9107 non-null   int64\n",
      " 71  wr_11                          9107 non-null   int64\n",
      " 72  wr_12                          9107 non-null   int64\n",
      " 73  wr_13                          9107 non-null   int64\n",
      " 74  race_Arab                      9107 non-null   int64\n",
      " 75  race_Asian                     9107 non-null   int64\n",
      " 76  race_Black                     9107 non-null   int64\n",
      " 77  race_Indigenous Australian     9107 non-null   int64\n",
      " 78  race_Native American           9107 non-null   int64\n",
      " 79  race_Other                     9107 non-null   int64\n",
      " 80  race_White                     9107 non-null   int64\n",
      " 81  religion_Agnostic              9107 non-null   int64\n",
      " 82  religion_Atheist               9107 non-null   int64\n",
      " 83  religion_Buddhist              9107 non-null   int64\n",
      " 84  religion_Christian_Catholic    9107 non-null   int64\n",
      " 85  religion_Christian_Mormon      9107 non-null   int64\n",
      " 86  religion_Christian_Protestant  9107 non-null   int64\n",
      " 87  religion_Christian_Other       9107 non-null   int64\n",
      " 88  religion_Hindu                 9107 non-null   int64\n",
      " 89  religion_Jewish                9107 non-null   int64\n",
      " 90  religion_Muslim                9107 non-null   int64\n",
      " 91  religion_Sikh                  9107 non-null   int64\n",
      " 92  religion_Other                 9107 non-null   int64\n",
      "dtypes: int64(93)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop(['index'],axis=1)\n",
    "test_df = test_df.drop(['race'],axis=1)\n",
    "test_df = test_df.drop(['religion'],axis=1)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182124f6",
   "metadata": {},
   "source": [
    "# train_df 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12184e3",
   "metadata": {},
   "source": [
    "train data 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115802de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 78 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   index       36425 non-null  int64  \n",
      " 1   QaA         36425 non-null  float64\n",
      " 2   QaE         36425 non-null  int64  \n",
      " 3   QbA         36425 non-null  float64\n",
      " 4   QbE         36425 non-null  int64  \n",
      " 5   QcA         36425 non-null  float64\n",
      " 6   QcE         36425 non-null  int64  \n",
      " 7   QdA         36425 non-null  float64\n",
      " 8   QdE         36425 non-null  int64  \n",
      " 9   QeA         36425 non-null  float64\n",
      " 10  QeE         36425 non-null  int64  \n",
      " 11  QfA         36425 non-null  float64\n",
      " 12  QfE         36425 non-null  int64  \n",
      " 13  QgA         36425 non-null  float64\n",
      " 14  QgE         36425 non-null  int64  \n",
      " 15  QhA         36425 non-null  float64\n",
      " 16  QhE         36425 non-null  int64  \n",
      " 17  QiA         36425 non-null  float64\n",
      " 18  QiE         36425 non-null  int64  \n",
      " 19  QjA         36425 non-null  float64\n",
      " 20  QjE         36425 non-null  int64  \n",
      " 21  QkA         36425 non-null  float64\n",
      " 22  QkE         36425 non-null  int64  \n",
      " 23  QlA         36425 non-null  float64\n",
      " 24  QlE         36425 non-null  int64  \n",
      " 25  QmA         36425 non-null  float64\n",
      " 26  QmE         36425 non-null  int64  \n",
      " 27  QnA         36425 non-null  float64\n",
      " 28  QnE         36425 non-null  int64  \n",
      " 29  QoA         36425 non-null  float64\n",
      " 30  QoE         36425 non-null  int64  \n",
      " 31  QpA         36425 non-null  float64\n",
      " 32  QpE         36425 non-null  int64  \n",
      " 33  QqA         36425 non-null  float64\n",
      " 34  QqE         36425 non-null  int64  \n",
      " 35  QrA         36425 non-null  float64\n",
      " 36  QrE         36425 non-null  int64  \n",
      " 37  QsA         36425 non-null  float64\n",
      " 38  QsE         36425 non-null  int64  \n",
      " 39  QtA         36425 non-null  float64\n",
      " 40  QtE         36425 non-null  int64  \n",
      " 41  age_group   36425 non-null  object \n",
      " 42  education   36425 non-null  int64  \n",
      " 43  engnat      36425 non-null  int64  \n",
      " 44  familysize  36425 non-null  int64  \n",
      " 45  gender      36425 non-null  object \n",
      " 46  hand        36425 non-null  int64  \n",
      " 47  married     36425 non-null  int64  \n",
      " 48  race        36425 non-null  object \n",
      " 49  religion    36425 non-null  object \n",
      " 50  tp01        36425 non-null  int64  \n",
      " 51  tp02        36425 non-null  int64  \n",
      " 52  tp03        36425 non-null  int64  \n",
      " 53  tp04        36425 non-null  int64  \n",
      " 54  tp05        36425 non-null  int64  \n",
      " 55  tp06        36425 non-null  int64  \n",
      " 56  tp07        36425 non-null  int64  \n",
      " 57  tp08        36425 non-null  int64  \n",
      " 58  tp09        36425 non-null  int64  \n",
      " 59  tp10        36425 non-null  int64  \n",
      " 60  urban       36425 non-null  int64  \n",
      " 61  voted       36425 non-null  int64  \n",
      " 62  wf_01       36425 non-null  int64  \n",
      " 63  wf_02       36425 non-null  int64  \n",
      " 64  wf_03       36425 non-null  int64  \n",
      " 65  wr_01       36425 non-null  int64  \n",
      " 66  wr_02       36425 non-null  int64  \n",
      " 67  wr_03       36425 non-null  int64  \n",
      " 68  wr_04       36425 non-null  int64  \n",
      " 69  wr_05       36425 non-null  int64  \n",
      " 70  wr_06       36425 non-null  int64  \n",
      " 71  wr_07       36425 non-null  int64  \n",
      " 72  wr_08       36425 non-null  int64  \n",
      " 73  wr_09       36425 non-null  int64  \n",
      " 74  wr_10       36425 non-null  int64  \n",
      " 75  wr_11       36425 non-null  int64  \n",
      " 76  wr_12       36425 non-null  int64  \n",
      " 77  wr_13       36425 non-null  int64  \n",
      "dtypes: float64(20), int64(54), object(4)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21172a24",
   "metadata": {},
   "source": [
    "'gender'전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e1c452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "36420    0\n",
       "36421    1\n",
       "36422    1\n",
       "36423    0\n",
       "36424    0\n",
       "Name: gender, Length: 36425, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = train_df['gender']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "gender_pre = encoder.transform(items)\n",
    "\n",
    "train_df['gender']= gender_pre \n",
    "train_df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98dbebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 78 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   index       36425 non-null  int64  \n",
      " 1   QaA         36425 non-null  float64\n",
      " 2   QaE         36425 non-null  int64  \n",
      " 3   QbA         36425 non-null  float64\n",
      " 4   QbE         36425 non-null  int64  \n",
      " 5   QcA         36425 non-null  float64\n",
      " 6   QcE         36425 non-null  int64  \n",
      " 7   QdA         36425 non-null  float64\n",
      " 8   QdE         36425 non-null  int64  \n",
      " 9   QeA         36425 non-null  float64\n",
      " 10  QeE         36425 non-null  int64  \n",
      " 11  QfA         36425 non-null  float64\n",
      " 12  QfE         36425 non-null  int64  \n",
      " 13  QgA         36425 non-null  float64\n",
      " 14  QgE         36425 non-null  int64  \n",
      " 15  QhA         36425 non-null  float64\n",
      " 16  QhE         36425 non-null  int64  \n",
      " 17  QiA         36425 non-null  float64\n",
      " 18  QiE         36425 non-null  int64  \n",
      " 19  QjA         36425 non-null  float64\n",
      " 20  QjE         36425 non-null  int64  \n",
      " 21  QkA         36425 non-null  float64\n",
      " 22  QkE         36425 non-null  int64  \n",
      " 23  QlA         36425 non-null  float64\n",
      " 24  QlE         36425 non-null  int64  \n",
      " 25  QmA         36425 non-null  float64\n",
      " 26  QmE         36425 non-null  int64  \n",
      " 27  QnA         36425 non-null  float64\n",
      " 28  QnE         36425 non-null  int64  \n",
      " 29  QoA         36425 non-null  float64\n",
      " 30  QoE         36425 non-null  int64  \n",
      " 31  QpA         36425 non-null  float64\n",
      " 32  QpE         36425 non-null  int64  \n",
      " 33  QqA         36425 non-null  float64\n",
      " 34  QqE         36425 non-null  int64  \n",
      " 35  QrA         36425 non-null  float64\n",
      " 36  QrE         36425 non-null  int64  \n",
      " 37  QsA         36425 non-null  float64\n",
      " 38  QsE         36425 non-null  int64  \n",
      " 39  QtA         36425 non-null  float64\n",
      " 40  QtE         36425 non-null  int64  \n",
      " 41  age_group   36425 non-null  object \n",
      " 42  education   36425 non-null  int64  \n",
      " 43  engnat      36425 non-null  int64  \n",
      " 44  familysize  36425 non-null  int64  \n",
      " 45  gender      36425 non-null  int32  \n",
      " 46  hand        36425 non-null  int64  \n",
      " 47  married     36425 non-null  int64  \n",
      " 48  race        36425 non-null  object \n",
      " 49  religion    36425 non-null  object \n",
      " 50  tp01        36425 non-null  int64  \n",
      " 51  tp02        36425 non-null  int64  \n",
      " 52  tp03        36425 non-null  int64  \n",
      " 53  tp04        36425 non-null  int64  \n",
      " 54  tp05        36425 non-null  int64  \n",
      " 55  tp06        36425 non-null  int64  \n",
      " 56  tp07        36425 non-null  int64  \n",
      " 57  tp08        36425 non-null  int64  \n",
      " 58  tp09        36425 non-null  int64  \n",
      " 59  tp10        36425 non-null  int64  \n",
      " 60  urban       36425 non-null  int64  \n",
      " 61  voted       36425 non-null  int64  \n",
      " 62  wf_01       36425 non-null  int64  \n",
      " 63  wf_02       36425 non-null  int64  \n",
      " 64  wf_03       36425 non-null  int64  \n",
      " 65  wr_01       36425 non-null  int64  \n",
      " 66  wr_02       36425 non-null  int64  \n",
      " 67  wr_03       36425 non-null  int64  \n",
      " 68  wr_04       36425 non-null  int64  \n",
      " 69  wr_05       36425 non-null  int64  \n",
      " 70  wr_06       36425 non-null  int64  \n",
      " 71  wr_07       36425 non-null  int64  \n",
      " 72  wr_08       36425 non-null  int64  \n",
      " 73  wr_09       36425 non-null  int64  \n",
      " 74  wr_10       36425 non-null  int64  \n",
      " 75  wr_11       36425 non-null  int64  \n",
      " 76  wr_12       36425 non-null  int64  \n",
      " 77  wr_13       36425 non-null  int64  \n",
      "dtypes: float64(20), int32(1), int64(54), object(3)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d899a3",
   "metadata": {},
   "source": [
    "'age_group' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547342d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_group에서 \"s\" , \"+\" 제거\n",
    "train_df['age_group'] = train_df['age_group'].str.strip(\"s\")\n",
    "train_df['age_group'] = train_df['age_group'].str.strip(\"+\")\n",
    "# 문자열 -> 정수 변환\n",
    "train_df['age_group'] = pd.to_numeric(train_df['age_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edded5b",
   "metadata": {},
   "source": [
    "'race' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8209f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "      <th>race_Arab</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Indigenous Australian</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>5.0</td>\n",
       "      <td>359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>534</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1555</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>749</td>\n",
       "      <td>2.0</td>\n",
       "      <td>624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13398</td>\n",
       "      <td>4.0</td>\n",
       "      <td>549</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36420</th>\n",
       "      <td>16511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312</td>\n",
       "      <td>5.0</td>\n",
       "      <td>965</td>\n",
       "      <td>5.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36421</th>\n",
       "      <td>33507</td>\n",
       "      <td>3.0</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>602</td>\n",
       "      <td>2.0</td>\n",
       "      <td>703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36422</th>\n",
       "      <td>44917</td>\n",
       "      <td>2.0</td>\n",
       "      <td>617</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36423</th>\n",
       "      <td>36126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>613</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36424</th>\n",
       "      <td>42340</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1876</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36425 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  wr_11  \\\n",
       "0      43375  1.0   324  5.0  1067  5.0   359  1.0   709  1.0  ...      0   \n",
       "1       4486  1.0   534  5.0  1555  5.0  2024  1.0  1097  1.0  ...      0   \n",
       "2      10262  5.0   609  1.0   749  2.0   624  1.0  1833  3.0  ...      0   \n",
       "3      14088  4.0   182  1.0  2969  1.0  1955  4.0  4630  1.0  ...      0   \n",
       "4      13398  4.0   549  5.0  1679  5.0   481  3.0   595  1.0  ...      1   \n",
       "...      ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...    ...   \n",
       "36420  16511  1.0   312  5.0   965  5.0   499  1.0  1188  1.0  ...      1   \n",
       "36421  33507  3.0   474  4.0  1033  5.0   602  2.0   703  1.0  ...      1   \n",
       "36422  44917  2.0   617  4.0  1262  2.0   709  1.0  1063  2.0  ...      1   \n",
       "36423  36126  5.0   294  1.0   985  1.0   504  3.0   613  5.0  ...      1   \n",
       "36424  42340  3.0  1062  1.0  3111  2.0   899  1.0  1876  3.0  ...      1   \n",
       "\n",
       "       wr_12  wr_13  race_Arab  race_Asian  race_Black  \\\n",
       "0          1      1          0           0           0   \n",
       "1          1      1          0           1           0   \n",
       "2          1      0          0           0           0   \n",
       "3          1      1          0           0           0   \n",
       "4          1      1          0           0           0   \n",
       "...      ...    ...        ...         ...         ...   \n",
       "36420      1      1          0           0           1   \n",
       "36421      1      1          0           0           0   \n",
       "36422      1      1          0           0           0   \n",
       "36423      1      1          0           0           0   \n",
       "36424      1      1          0           0           0   \n",
       "\n",
       "       race_Indigenous Australian  race_Native American  race_Other  \\\n",
       "0                               0                     0           0   \n",
       "1                               0                     0           0   \n",
       "2                               0                     0           0   \n",
       "3                               0                     0           1   \n",
       "4                               0                     0           0   \n",
       "...                           ...                   ...         ...   \n",
       "36420                           0                     0           0   \n",
       "36421                           0                     0           0   \n",
       "36422                           0                     0           0   \n",
       "36423                           0                     0           0   \n",
       "36424                           0                     0           0   \n",
       "\n",
       "       race_White  \n",
       "0               1  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "36420           0  \n",
       "36421           1  \n",
       "36422           1  \n",
       "36423           1  \n",
       "36424           1  \n",
       "\n",
       "[36425 rows x 85 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_race = train_df['race']\n",
    "\n",
    "df = pd.DataFrame({'race':vote_race})\n",
    "race_onehot = pd.get_dummies(df)\n",
    "\n",
    "# 데이터 프레임에 추가\n",
    "train_df['race_Arab']= race_onehot['race_Arab']\n",
    "train_df['race_Asian']= race_onehot['race_Asian']\n",
    "train_df['race_Black']= race_onehot['race_Black']\n",
    "train_df['race_Indigenous Australian']= race_onehot['race_Indigenous Australian']\n",
    "train_df['race_Native American']= race_onehot['race_Native American']\n",
    "train_df['race_Other']= race_onehot['race_Other']\n",
    "train_df['race_White']= race_onehot['race_White']\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c1450",
   "metadata": {},
   "source": [
    "'religion' 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd51e8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>religion_Buddhist</th>\n",
       "      <th>religion_Christian_Catholic</th>\n",
       "      <th>religion_Christian_Mormon</th>\n",
       "      <th>religion_Christian_Protestant</th>\n",
       "      <th>religion_Christian_Other</th>\n",
       "      <th>religion_Hindu</th>\n",
       "      <th>religion_Jewish</th>\n",
       "      <th>religion_Muslim</th>\n",
       "      <th>religion_Sikh</th>\n",
       "      <th>religion_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>5.0</td>\n",
       "      <td>359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>534</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1555</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>749</td>\n",
       "      <td>2.0</td>\n",
       "      <td>624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13398</td>\n",
       "      <td>4.0</td>\n",
       "      <td>549</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36420</th>\n",
       "      <td>16511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312</td>\n",
       "      <td>5.0</td>\n",
       "      <td>965</td>\n",
       "      <td>5.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36421</th>\n",
       "      <td>33507</td>\n",
       "      <td>3.0</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>602</td>\n",
       "      <td>2.0</td>\n",
       "      <td>703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36422</th>\n",
       "      <td>44917</td>\n",
       "      <td>2.0</td>\n",
       "      <td>617</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36423</th>\n",
       "      <td>36126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>613</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36424</th>\n",
       "      <td>42340</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1876</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36425 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  \\\n",
       "0      43375  1.0   324  5.0  1067  5.0   359  1.0   709  1.0  ...   \n",
       "1       4486  1.0   534  5.0  1555  5.0  2024  1.0  1097  1.0  ...   \n",
       "2      10262  5.0   609  1.0   749  2.0   624  1.0  1833  3.0  ...   \n",
       "3      14088  4.0   182  1.0  2969  1.0  1955  4.0  4630  1.0  ...   \n",
       "4      13398  4.0   549  5.0  1679  5.0   481  3.0   595  1.0  ...   \n",
       "...      ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...   \n",
       "36420  16511  1.0   312  5.0   965  5.0   499  1.0  1188  1.0  ...   \n",
       "36421  33507  3.0   474  4.0  1033  5.0   602  2.0   703  1.0  ...   \n",
       "36422  44917  2.0   617  4.0  1262  2.0   709  1.0  1063  2.0  ...   \n",
       "36423  36126  5.0   294  1.0   985  1.0   504  3.0   613  5.0  ...   \n",
       "36424  42340  3.0  1062  1.0  3111  2.0   899  1.0  1876  3.0  ...   \n",
       "\n",
       "       religion_Buddhist  religion_Christian_Catholic  \\\n",
       "0                      0                            1   \n",
       "1                      0                            0   \n",
       "2                      0                            0   \n",
       "3                      0                            0   \n",
       "4                      0                            0   \n",
       "...                  ...                          ...   \n",
       "36420                  0                            0   \n",
       "36421                  0                            0   \n",
       "36422                  0                            0   \n",
       "36423                  0                            0   \n",
       "36424                  0                            0   \n",
       "\n",
       "       religion_Christian_Mormon  religion_Christian_Protestant  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "...                          ...                            ...   \n",
       "36420                          0                              0   \n",
       "36421                          0                              0   \n",
       "36422                          0                              0   \n",
       "36423                          0                              0   \n",
       "36424                          0                              0   \n",
       "\n",
       "       religion_Christian_Other  religion_Hindu  religion_Jewish  \\\n",
       "0                             0               0                0   \n",
       "1                             0               1                0   \n",
       "2                             1               0                0   \n",
       "3                             0               1                0   \n",
       "4                             0               0                0   \n",
       "...                         ...             ...              ...   \n",
       "36420                         0               0                0   \n",
       "36421                         0               0                1   \n",
       "36422                         0               0                0   \n",
       "36423                         0               0                0   \n",
       "36424                         0               0                0   \n",
       "\n",
       "       religion_Muslim  religion_Sikh  religion_Other  \n",
       "0                    0              0               0  \n",
       "1                    0              0               0  \n",
       "2                    0              0               0  \n",
       "3                    0              0               0  \n",
       "4                    0              0               1  \n",
       "...                ...            ...             ...  \n",
       "36420                0              0               1  \n",
       "36421                0              0               0  \n",
       "36422                0              0               0  \n",
       "36423                0              0               1  \n",
       "36424                0              0               1  \n",
       "\n",
       "[36425 rows x 97 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# religion\n",
    "vote_religion = train_df['religion']\n",
    "\n",
    "df = pd.DataFrame({'religion':vote_religion})\n",
    "religion_onehot = pd.get_dummies(df)\n",
    "\n",
    "# 데이터 프레임에 추가\n",
    "train_df['religion_Agnostic']= religion_onehot['religion_Agnostic']\n",
    "train_df['religion_Atheist']= religion_onehot['religion_Atheist']\n",
    "train_df['religion_Buddhist']= religion_onehot['religion_Buddhist']\n",
    "train_df['religion_Christian_Catholic']= religion_onehot['religion_Christian_Catholic']\n",
    "train_df['religion_Christian_Mormon']= religion_onehot['religion_Christian_Mormon']\n",
    "train_df['religion_Christian_Protestant']= religion_onehot['religion_Christian_Protestant']\n",
    "train_df['religion_Christian_Other']= religion_onehot['religion_Christian_Other']\n",
    "train_df['religion_Hindu']= religion_onehot['religion_Hindu']\n",
    "train_df['religion_Jewish']= religion_onehot['religion_Jewish']\n",
    "train_df['religion_Muslim']= religion_onehot['religion_Muslim']\n",
    "train_df['religion_Sikh']= religion_onehot['religion_Sikh']\n",
    "train_df['religion_Other']= religion_onehot['religion_Other']\n",
    "\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8330d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 97 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   index                          36425 non-null  int64  \n",
      " 1   QaA                            36425 non-null  float64\n",
      " 2   QaE                            36425 non-null  int64  \n",
      " 3   QbA                            36425 non-null  float64\n",
      " 4   QbE                            36425 non-null  int64  \n",
      " 5   QcA                            36425 non-null  float64\n",
      " 6   QcE                            36425 non-null  int64  \n",
      " 7   QdA                            36425 non-null  float64\n",
      " 8   QdE                            36425 non-null  int64  \n",
      " 9   QeA                            36425 non-null  float64\n",
      " 10  QeE                            36425 non-null  int64  \n",
      " 11  QfA                            36425 non-null  float64\n",
      " 12  QfE                            36425 non-null  int64  \n",
      " 13  QgA                            36425 non-null  float64\n",
      " 14  QgE                            36425 non-null  int64  \n",
      " 15  QhA                            36425 non-null  float64\n",
      " 16  QhE                            36425 non-null  int64  \n",
      " 17  QiA                            36425 non-null  float64\n",
      " 18  QiE                            36425 non-null  int64  \n",
      " 19  QjA                            36425 non-null  float64\n",
      " 20  QjE                            36425 non-null  int64  \n",
      " 21  QkA                            36425 non-null  float64\n",
      " 22  QkE                            36425 non-null  int64  \n",
      " 23  QlA                            36425 non-null  float64\n",
      " 24  QlE                            36425 non-null  int64  \n",
      " 25  QmA                            36425 non-null  float64\n",
      " 26  QmE                            36425 non-null  int64  \n",
      " 27  QnA                            36425 non-null  float64\n",
      " 28  QnE                            36425 non-null  int64  \n",
      " 29  QoA                            36425 non-null  float64\n",
      " 30  QoE                            36425 non-null  int64  \n",
      " 31  QpA                            36425 non-null  float64\n",
      " 32  QpE                            36425 non-null  int64  \n",
      " 33  QqA                            36425 non-null  float64\n",
      " 34  QqE                            36425 non-null  int64  \n",
      " 35  QrA                            36425 non-null  float64\n",
      " 36  QrE                            36425 non-null  int64  \n",
      " 37  QsA                            36425 non-null  float64\n",
      " 38  QsE                            36425 non-null  int64  \n",
      " 39  QtA                            36425 non-null  float64\n",
      " 40  QtE                            36425 non-null  int64  \n",
      " 41  age_group                      36425 non-null  int64  \n",
      " 42  education                      36425 non-null  int64  \n",
      " 43  engnat                         36425 non-null  int64  \n",
      " 44  familysize                     36425 non-null  int64  \n",
      " 45  gender                         36425 non-null  int32  \n",
      " 46  hand                           36425 non-null  int64  \n",
      " 47  married                        36425 non-null  int64  \n",
      " 48  race                           36425 non-null  object \n",
      " 49  religion                       36425 non-null  object \n",
      " 50  tp01                           36425 non-null  int64  \n",
      " 51  tp02                           36425 non-null  int64  \n",
      " 52  tp03                           36425 non-null  int64  \n",
      " 53  tp04                           36425 non-null  int64  \n",
      " 54  tp05                           36425 non-null  int64  \n",
      " 55  tp06                           36425 non-null  int64  \n",
      " 56  tp07                           36425 non-null  int64  \n",
      " 57  tp08                           36425 non-null  int64  \n",
      " 58  tp09                           36425 non-null  int64  \n",
      " 59  tp10                           36425 non-null  int64  \n",
      " 60  urban                          36425 non-null  int64  \n",
      " 61  voted                          36425 non-null  int64  \n",
      " 62  wf_01                          36425 non-null  int64  \n",
      " 63  wf_02                          36425 non-null  int64  \n",
      " 64  wf_03                          36425 non-null  int64  \n",
      " 65  wr_01                          36425 non-null  int64  \n",
      " 66  wr_02                          36425 non-null  int64  \n",
      " 67  wr_03                          36425 non-null  int64  \n",
      " 68  wr_04                          36425 non-null  int64  \n",
      " 69  wr_05                          36425 non-null  int64  \n",
      " 70  wr_06                          36425 non-null  int64  \n",
      " 71  wr_07                          36425 non-null  int64  \n",
      " 72  wr_08                          36425 non-null  int64  \n",
      " 73  wr_09                          36425 non-null  int64  \n",
      " 74  wr_10                          36425 non-null  int64  \n",
      " 75  wr_11                          36425 non-null  int64  \n",
      " 76  wr_12                          36425 non-null  int64  \n",
      " 77  wr_13                          36425 non-null  int64  \n",
      " 78  race_Arab                      36425 non-null  uint8  \n",
      " 79  race_Asian                     36425 non-null  uint8  \n",
      " 80  race_Black                     36425 non-null  uint8  \n",
      " 81  race_Indigenous Australian     36425 non-null  uint8  \n",
      " 82  race_Native American           36425 non-null  uint8  \n",
      " 83  race_Other                     36425 non-null  uint8  \n",
      " 84  race_White                     36425 non-null  uint8  \n",
      " 85  religion_Agnostic              36425 non-null  uint8  \n",
      " 86  religion_Atheist               36425 non-null  uint8  \n",
      " 87  religion_Buddhist              36425 non-null  uint8  \n",
      " 88  religion_Christian_Catholic    36425 non-null  uint8  \n",
      " 89  religion_Christian_Mormon      36425 non-null  uint8  \n",
      " 90  religion_Christian_Protestant  36425 non-null  uint8  \n",
      " 91  religion_Christian_Other       36425 non-null  uint8  \n",
      " 92  religion_Hindu                 36425 non-null  uint8  \n",
      " 93  religion_Jewish                36425 non-null  uint8  \n",
      " 94  religion_Muslim                36425 non-null  uint8  \n",
      " 95  religion_Sikh                  36425 non-null  uint8  \n",
      " 96  religion_Other                 36425 non-null  uint8  \n",
      "dtypes: float64(20), int32(1), int64(55), object(2), uint8(19)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b35924",
   "metadata": {},
   "source": [
    "데이터 타입 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c957e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 97 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   index                          36425 non-null  int64 \n",
      " 1   QaA                            36425 non-null  int64 \n",
      " 2   QaE                            36425 non-null  int64 \n",
      " 3   QbA                            36425 non-null  int64 \n",
      " 4   QbE                            36425 non-null  int64 \n",
      " 5   QcA                            36425 non-null  int64 \n",
      " 6   QcE                            36425 non-null  int64 \n",
      " 7   QdA                            36425 non-null  int64 \n",
      " 8   QdE                            36425 non-null  int64 \n",
      " 9   QeA                            36425 non-null  int64 \n",
      " 10  QeE                            36425 non-null  int64 \n",
      " 11  QfA                            36425 non-null  int64 \n",
      " 12  QfE                            36425 non-null  int64 \n",
      " 13  QgA                            36425 non-null  int64 \n",
      " 14  QgE                            36425 non-null  int64 \n",
      " 15  QhA                            36425 non-null  int64 \n",
      " 16  QhE                            36425 non-null  int64 \n",
      " 17  QiA                            36425 non-null  int64 \n",
      " 18  QiE                            36425 non-null  int64 \n",
      " 19  QjA                            36425 non-null  int64 \n",
      " 20  QjE                            36425 non-null  int64 \n",
      " 21  QkA                            36425 non-null  int64 \n",
      " 22  QkE                            36425 non-null  int64 \n",
      " 23  QlA                            36425 non-null  int64 \n",
      " 24  QlE                            36425 non-null  int64 \n",
      " 25  QmA                            36425 non-null  int64 \n",
      " 26  QmE                            36425 non-null  int64 \n",
      " 27  QnA                            36425 non-null  int64 \n",
      " 28  QnE                            36425 non-null  int64 \n",
      " 29  QoA                            36425 non-null  int64 \n",
      " 30  QoE                            36425 non-null  int64 \n",
      " 31  QpA                            36425 non-null  int64 \n",
      " 32  QpE                            36425 non-null  int64 \n",
      " 33  QqA                            36425 non-null  int64 \n",
      " 34  QqE                            36425 non-null  int64 \n",
      " 35  QrA                            36425 non-null  int64 \n",
      " 36  QrE                            36425 non-null  int64 \n",
      " 37  QsA                            36425 non-null  int64 \n",
      " 38  QsE                            36425 non-null  int64 \n",
      " 39  QtA                            36425 non-null  int64 \n",
      " 40  QtE                            36425 non-null  int64 \n",
      " 41  age_group                      36425 non-null  int64 \n",
      " 42  education                      36425 non-null  int64 \n",
      " 43  engnat                         36425 non-null  int64 \n",
      " 44  familysize                     36425 non-null  int64 \n",
      " 45  gender                         36425 non-null  int64 \n",
      " 46  hand                           36425 non-null  int64 \n",
      " 47  married                        36425 non-null  int64 \n",
      " 48  race                           36425 non-null  object\n",
      " 49  religion                       36425 non-null  object\n",
      " 50  tp01                           36425 non-null  int64 \n",
      " 51  tp02                           36425 non-null  int64 \n",
      " 52  tp03                           36425 non-null  int64 \n",
      " 53  tp04                           36425 non-null  int64 \n",
      " 54  tp05                           36425 non-null  int64 \n",
      " 55  tp06                           36425 non-null  int64 \n",
      " 56  tp07                           36425 non-null  int64 \n",
      " 57  tp08                           36425 non-null  int64 \n",
      " 58  tp09                           36425 non-null  int64 \n",
      " 59  tp10                           36425 non-null  int64 \n",
      " 60  urban                          36425 non-null  int64 \n",
      " 61  voted                          36425 non-null  int64 \n",
      " 62  wf_01                          36425 non-null  int64 \n",
      " 63  wf_02                          36425 non-null  int64 \n",
      " 64  wf_03                          36425 non-null  int64 \n",
      " 65  wr_01                          36425 non-null  int64 \n",
      " 66  wr_02                          36425 non-null  int64 \n",
      " 67  wr_03                          36425 non-null  int64 \n",
      " 68  wr_04                          36425 non-null  int64 \n",
      " 69  wr_05                          36425 non-null  int64 \n",
      " 70  wr_06                          36425 non-null  int64 \n",
      " 71  wr_07                          36425 non-null  int64 \n",
      " 72  wr_08                          36425 non-null  int64 \n",
      " 73  wr_09                          36425 non-null  int64 \n",
      " 74  wr_10                          36425 non-null  int64 \n",
      " 75  wr_11                          36425 non-null  int64 \n",
      " 76  wr_12                          36425 non-null  int64 \n",
      " 77  wr_13                          36425 non-null  int64 \n",
      " 78  race_Arab                      36425 non-null  int64 \n",
      " 79  race_Asian                     36425 non-null  int64 \n",
      " 80  race_Black                     36425 non-null  int64 \n",
      " 81  race_Indigenous Australian     36425 non-null  int64 \n",
      " 82  race_Native American           36425 non-null  int64 \n",
      " 83  race_Other                     36425 non-null  int64 \n",
      " 84  race_White                     36425 non-null  int64 \n",
      " 85  religion_Agnostic              36425 non-null  int64 \n",
      " 86  religion_Atheist               36425 non-null  int64 \n",
      " 87  religion_Buddhist              36425 non-null  int64 \n",
      " 88  religion_Christian_Catholic    36425 non-null  int64 \n",
      " 89  religion_Christian_Mormon      36425 non-null  int64 \n",
      " 90  religion_Christian_Protestant  36425 non-null  int64 \n",
      " 91  religion_Christian_Other       36425 non-null  int64 \n",
      " 92  religion_Hindu                 36425 non-null  int64 \n",
      " 93  religion_Jewish                36425 non-null  int64 \n",
      " 94  religion_Muslim                36425 non-null  int64 \n",
      " 95  religion_Sikh                  36425 non-null  int64 \n",
      " 96  religion_Other                 36425 non-null  int64 \n",
      "dtypes: int64(95), object(2)\n",
      "memory usage: 27.0+ MB\n"
     ]
    }
   ],
   "source": [
    "for i in train_df:\n",
    "    if i.find('A') is not -1:\n",
    "        train_df = train_df.astype({i:'int64'})\n",
    "\n",
    "for i in train_df:\n",
    "    if i.find('race_') is not -1:\n",
    "        train_df = train_df.astype({i:'int64'})\n",
    "\n",
    "for i in train_df:\n",
    "    if i.find('religion_') is not -1:\n",
    "        train_df = train_df.astype({i:'int64'})\n",
    "\n",
    "for i in train_df:\n",
    "    if i.find('gender') is not -1:\n",
    "        train_df = train_df.astype({i:'int64'})\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46b252",
   "metadata": {},
   "source": [
    "'voted' 컬럼 위치 변경/ 'index', 'race', 'religion' 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf7660b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   voted   36425 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 284.7 KB\n"
     ]
    }
   ],
   "source": [
    "vote_ex_list = {}\n",
    "vote_ex_df = pd.DataFrame(vote_ex_list)\n",
    "vote_ex_df['voted'] = train_df['voted']\n",
    "vote_ex_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e547381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['index'],axis=1)\n",
    "train_df = train_df.drop(['race'],axis=1)\n",
    "train_df = train_df.drop(['religion'],axis=1)\n",
    "train_df = train_df.drop(['voted'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3025275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36425 entries, 0 to 36424\n",
      "Data columns (total 94 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   QaA                            36425 non-null  int64\n",
      " 1   QaE                            36425 non-null  int64\n",
      " 2   QbA                            36425 non-null  int64\n",
      " 3   QbE                            36425 non-null  int64\n",
      " 4   QcA                            36425 non-null  int64\n",
      " 5   QcE                            36425 non-null  int64\n",
      " 6   QdA                            36425 non-null  int64\n",
      " 7   QdE                            36425 non-null  int64\n",
      " 8   QeA                            36425 non-null  int64\n",
      " 9   QeE                            36425 non-null  int64\n",
      " 10  QfA                            36425 non-null  int64\n",
      " 11  QfE                            36425 non-null  int64\n",
      " 12  QgA                            36425 non-null  int64\n",
      " 13  QgE                            36425 non-null  int64\n",
      " 14  QhA                            36425 non-null  int64\n",
      " 15  QhE                            36425 non-null  int64\n",
      " 16  QiA                            36425 non-null  int64\n",
      " 17  QiE                            36425 non-null  int64\n",
      " 18  QjA                            36425 non-null  int64\n",
      " 19  QjE                            36425 non-null  int64\n",
      " 20  QkA                            36425 non-null  int64\n",
      " 21  QkE                            36425 non-null  int64\n",
      " 22  QlA                            36425 non-null  int64\n",
      " 23  QlE                            36425 non-null  int64\n",
      " 24  QmA                            36425 non-null  int64\n",
      " 25  QmE                            36425 non-null  int64\n",
      " 26  QnA                            36425 non-null  int64\n",
      " 27  QnE                            36425 non-null  int64\n",
      " 28  QoA                            36425 non-null  int64\n",
      " 29  QoE                            36425 non-null  int64\n",
      " 30  QpA                            36425 non-null  int64\n",
      " 31  QpE                            36425 non-null  int64\n",
      " 32  QqA                            36425 non-null  int64\n",
      " 33  QqE                            36425 non-null  int64\n",
      " 34  QrA                            36425 non-null  int64\n",
      " 35  QrE                            36425 non-null  int64\n",
      " 36  QsA                            36425 non-null  int64\n",
      " 37  QsE                            36425 non-null  int64\n",
      " 38  QtA                            36425 non-null  int64\n",
      " 39  QtE                            36425 non-null  int64\n",
      " 40  age_group                      36425 non-null  int64\n",
      " 41  education                      36425 non-null  int64\n",
      " 42  engnat                         36425 non-null  int64\n",
      " 43  familysize                     36425 non-null  int64\n",
      " 44  gender                         36425 non-null  int64\n",
      " 45  hand                           36425 non-null  int64\n",
      " 46  married                        36425 non-null  int64\n",
      " 47  tp01                           36425 non-null  int64\n",
      " 48  tp02                           36425 non-null  int64\n",
      " 49  tp03                           36425 non-null  int64\n",
      " 50  tp04                           36425 non-null  int64\n",
      " 51  tp05                           36425 non-null  int64\n",
      " 52  tp06                           36425 non-null  int64\n",
      " 53  tp07                           36425 non-null  int64\n",
      " 54  tp08                           36425 non-null  int64\n",
      " 55  tp09                           36425 non-null  int64\n",
      " 56  tp10                           36425 non-null  int64\n",
      " 57  urban                          36425 non-null  int64\n",
      " 58  wf_01                          36425 non-null  int64\n",
      " 59  wf_02                          36425 non-null  int64\n",
      " 60  wf_03                          36425 non-null  int64\n",
      " 61  wr_01                          36425 non-null  int64\n",
      " 62  wr_02                          36425 non-null  int64\n",
      " 63  wr_03                          36425 non-null  int64\n",
      " 64  wr_04                          36425 non-null  int64\n",
      " 65  wr_05                          36425 non-null  int64\n",
      " 66  wr_06                          36425 non-null  int64\n",
      " 67  wr_07                          36425 non-null  int64\n",
      " 68  wr_08                          36425 non-null  int64\n",
      " 69  wr_09                          36425 non-null  int64\n",
      " 70  wr_10                          36425 non-null  int64\n",
      " 71  wr_11                          36425 non-null  int64\n",
      " 72  wr_12                          36425 non-null  int64\n",
      " 73  wr_13                          36425 non-null  int64\n",
      " 74  race_Arab                      36425 non-null  int64\n",
      " 75  race_Asian                     36425 non-null  int64\n",
      " 76  race_Black                     36425 non-null  int64\n",
      " 77  race_Indigenous Australian     36425 non-null  int64\n",
      " 78  race_Native American           36425 non-null  int64\n",
      " 79  race_Other                     36425 non-null  int64\n",
      " 80  race_White                     36425 non-null  int64\n",
      " 81  religion_Agnostic              36425 non-null  int64\n",
      " 82  religion_Atheist               36425 non-null  int64\n",
      " 83  religion_Buddhist              36425 non-null  int64\n",
      " 84  religion_Christian_Catholic    36425 non-null  int64\n",
      " 85  religion_Christian_Mormon      36425 non-null  int64\n",
      " 86  religion_Christian_Protestant  36425 non-null  int64\n",
      " 87  religion_Christian_Other       36425 non-null  int64\n",
      " 88  religion_Hindu                 36425 non-null  int64\n",
      " 89  religion_Jewish                36425 non-null  int64\n",
      " 90  religion_Muslim                36425 non-null  int64\n",
      " 91  religion_Sikh                  36425 non-null  int64\n",
      " 92  religion_Other                 36425 non-null  int64\n",
      " 93  voted                          36425 non-null  int64\n",
      "dtypes: int64(94)\n",
      "memory usage: 26.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_df['voted'] = vote_ex_df['voted']\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331764c",
   "metadata": {},
   "source": [
    "# 모델구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98a1a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29140, 93) (7285, 93)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X = train_df.iloc[:, :-1].to_numpy()\n",
    "y = train_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "final_lgbm = LGBMClassifier(learning_rate=0.05, max_depth=9, num_iterations=200, random_state=0)\n",
    "ada_clf = AdaBoostClassifier(learning_rate=0.1, n_estimators=10, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier(max_depth = 1, min_samples_split=2, random_state=0)\n",
    "rf_clf = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators=400, random_state=0)\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1, max_depth=1, num_iterations= 200, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b94f09",
   "metadata": {},
   "source": [
    "사용 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5736fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval_5(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "    \n",
    "def get_clf_eval_4(y_test, pred=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, pred_proba_, thresholds):\n",
    "    for m_threshold in thresholds:\n",
    "        print(m_threshold)\n",
    "        binarizer = Binarizer(threshold = m_threshold).fit(pred_proba_)\n",
    "        m_predict = binarizer.transform(pred_proba_)\n",
    "        get_clf_eval_5(y_test, m_predict, pred_proba_c1)\n",
    "\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0],1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    \n",
    "    print(model.__class__.__name__ , 'model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t 폴드 세트:', folder_counter, '시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        test_pred[:, folder_counter]=model.predict(X_test_n)\n",
    "        \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624cc66",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b83677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29140, 93) (29140,)\n",
      "(31868, 93) (31868,)\n",
      "1    15934\n",
      "0    15934\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state = 0)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_train_over.shape, y_train_over.shape)\n",
    "print(pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a5ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.676853\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-logloss:0.663717\n",
      "[2]\tvalidation_0-logloss:0.653102\n",
      "[3]\tvalidation_0-logloss:0.644399\n",
      "[4]\tvalidation_0-logloss:0.637249\n",
      "[5]\tvalidation_0-logloss:0.63146\n",
      "[6]\tvalidation_0-logloss:0.626668\n",
      "[7]\tvalidation_0-logloss:0.622748\n",
      "[8]\tvalidation_0-logloss:0.619527\n",
      "[9]\tvalidation_0-logloss:0.616278\n",
      "[10]\tvalidation_0-logloss:0.61364\n",
      "[11]\tvalidation_0-logloss:0.611003\n",
      "[12]\tvalidation_0-logloss:0.608926\n",
      "[13]\tvalidation_0-logloss:0.606751\n",
      "[14]\tvalidation_0-logloss:0.605025\n",
      "[15]\tvalidation_0-logloss:0.60339\n",
      "[16]\tvalidation_0-logloss:0.601654\n",
      "[17]\tvalidation_0-logloss:0.600309\n",
      "[18]\tvalidation_0-logloss:0.599002\n",
      "[19]\tvalidation_0-logloss:0.597568\n",
      "[20]\tvalidation_0-logloss:0.596478\n",
      "[21]\tvalidation_0-logloss:0.595441\n",
      "[22]\tvalidation_0-logloss:0.593952\n",
      "[23]\tvalidation_0-logloss:0.592828\n",
      "[24]\tvalidation_0-logloss:0.59197\n",
      "[25]\tvalidation_0-logloss:0.591175\n",
      "[26]\tvalidation_0-logloss:0.590254\n",
      "[27]\tvalidation_0-logloss:0.589591\n",
      "[28]\tvalidation_0-logloss:0.58848\n",
      "[29]\tvalidation_0-logloss:0.587953\n",
      "[30]\tvalidation_0-logloss:0.587194\n",
      "[31]\tvalidation_0-logloss:0.586632\n",
      "[32]\tvalidation_0-logloss:0.585727\n",
      "[33]\tvalidation_0-logloss:0.585327\n",
      "[34]\tvalidation_0-logloss:0.584986\n",
      "[35]\tvalidation_0-logloss:0.584377\n",
      "[36]\tvalidation_0-logloss:0.583974\n",
      "[37]\tvalidation_0-logloss:0.583258\n",
      "[38]\tvalidation_0-logloss:0.582892\n",
      "[39]\tvalidation_0-logloss:0.582593\n",
      "[40]\tvalidation_0-logloss:0.582347\n",
      "[41]\tvalidation_0-logloss:0.58186\n",
      "[42]\tvalidation_0-logloss:0.581528\n",
      "[43]\tvalidation_0-logloss:0.581284\n",
      "[44]\tvalidation_0-logloss:0.581001\n",
      "[45]\tvalidation_0-logloss:0.580709\n",
      "[46]\tvalidation_0-logloss:0.580492\n",
      "[47]\tvalidation_0-logloss:0.580251\n",
      "[48]\tvalidation_0-logloss:0.579869\n",
      "[49]\tvalidation_0-logloss:0.579674\n",
      "[50]\tvalidation_0-logloss:0.57952\n",
      "[51]\tvalidation_0-logloss:0.579271\n",
      "[52]\tvalidation_0-logloss:0.57878\n",
      "[53]\tvalidation_0-logloss:0.578567\n",
      "[54]\tvalidation_0-logloss:0.578388\n",
      "[55]\tvalidation_0-logloss:0.578232\n",
      "[56]\tvalidation_0-logloss:0.578077\n",
      "[57]\tvalidation_0-logloss:0.577819\n",
      "[58]\tvalidation_0-logloss:0.577509\n",
      "[59]\tvalidation_0-logloss:0.577305\n",
      "[60]\tvalidation_0-logloss:0.577141\n",
      "[61]\tvalidation_0-logloss:0.577039\n",
      "[62]\tvalidation_0-logloss:0.576924\n",
      "[63]\tvalidation_0-logloss:0.576534\n",
      "[64]\tvalidation_0-logloss:0.576426\n",
      "[65]\tvalidation_0-logloss:0.576295\n",
      "[66]\tvalidation_0-logloss:0.576188\n",
      "[67]\tvalidation_0-logloss:0.575914\n",
      "[68]\tvalidation_0-logloss:0.575765\n",
      "[69]\tvalidation_0-logloss:0.575679\n",
      "[70]\tvalidation_0-logloss:0.575431\n",
      "[71]\tvalidation_0-logloss:0.575315\n",
      "[72]\tvalidation_0-logloss:0.575147\n",
      "[73]\tvalidation_0-logloss:0.574959\n",
      "[74]\tvalidation_0-logloss:0.574853\n",
      "[75]\tvalidation_0-logloss:0.574778\n",
      "[76]\tvalidation_0-logloss:0.574691\n",
      "[77]\tvalidation_0-logloss:0.574623\n",
      "[78]\tvalidation_0-logloss:0.574564\n",
      "[79]\tvalidation_0-logloss:0.574437\n",
      "[80]\tvalidation_0-logloss:0.574288\n",
      "[81]\tvalidation_0-logloss:0.574221\n",
      "[82]\tvalidation_0-logloss:0.573999\n",
      "[83]\tvalidation_0-logloss:0.573874\n",
      "[84]\tvalidation_0-logloss:0.573769\n",
      "[85]\tvalidation_0-logloss:0.57368\n",
      "[86]\tvalidation_0-logloss:0.573554\n",
      "[87]\tvalidation_0-logloss:0.573501\n",
      "[88]\tvalidation_0-logloss:0.573215\n",
      "[89]\tvalidation_0-logloss:0.573136\n",
      "[90]\tvalidation_0-logloss:0.573048\n",
      "[91]\tvalidation_0-logloss:0.572855\n",
      "[92]\tvalidation_0-logloss:0.572738\n",
      "[93]\tvalidation_0-logloss:0.572688\n",
      "[94]\tvalidation_0-logloss:0.572767\n",
      "[95]\tvalidation_0-logloss:0.572727\n",
      "[96]\tvalidation_0-logloss:0.572693\n",
      "[97]\tvalidation_0-logloss:0.572515\n",
      "[98]\tvalidation_0-logloss:0.572408\n",
      "[99]\tvalidation_0-logloss:0.572348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(max_depth=1, num_iterations=200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = [(X_test, y_test)]\n",
    "\n",
    "rf_clf.fit(X_train_over, y_train_over)\n",
    "dt_clf.fit(X_train_over, y_train_over)\n",
    "ada_clf.fit(X_train_over, y_train_over)\n",
    "xgb_clf.fit(X_train_over, y_train_over, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set= evals, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47191b5a",
   "metadata": {},
   "source": [
    "kFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f811336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier model 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "AdaBoostClassifier model 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "DecisionTreeClassifier model 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "RandomForestClassifier model 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n"
     ]
    }
   ],
   "source": [
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_clf, X_train_over, y_train_over, X_test, 6)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train_over, y_train_over, X_test, 6)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train_over, y_train_over, X_test, 6)\n",
    "rf_train, rf_test = get_stacking_base_datasets( rf_clf, X_train_over, y_train_over, X_test, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "689cd410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.68238\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.672596\n",
      "[3]\tvalid_0's binary_logloss: 0.663729\n",
      "[4]\tvalid_0's binary_logloss: 0.655712\n",
      "[5]\tvalid_0's binary_logloss: 0.64841\n",
      "[6]\tvalid_0's binary_logloss: 0.64158\n",
      "[7]\tvalid_0's binary_logloss: 0.635511\n",
      "[8]\tvalid_0's binary_logloss: 0.6299\n",
      "[9]\tvalid_0's binary_logloss: 0.624631\n",
      "[10]\tvalid_0's binary_logloss: 0.619797\n",
      "[11]\tvalid_0's binary_logloss: 0.615503\n",
      "[12]\tvalid_0's binary_logloss: 0.611437\n",
      "[13]\tvalid_0's binary_logloss: 0.607614\n",
      "[14]\tvalid_0's binary_logloss: 0.604164\n",
      "[15]\tvalid_0's binary_logloss: 0.601035\n",
      "[16]\tvalid_0's binary_logloss: 0.598127\n",
      "[17]\tvalid_0's binary_logloss: 0.595472\n",
      "[18]\tvalid_0's binary_logloss: 0.59294\n",
      "[19]\tvalid_0's binary_logloss: 0.590516\n",
      "[20]\tvalid_0's binary_logloss: 0.588318\n",
      "[21]\tvalid_0's binary_logloss: 0.586293\n",
      "[22]\tvalid_0's binary_logloss: 0.584378\n",
      "[23]\tvalid_0's binary_logloss: 0.582594\n",
      "[24]\tvalid_0's binary_logloss: 0.581054\n",
      "[25]\tvalid_0's binary_logloss: 0.579541\n",
      "[26]\tvalid_0's binary_logloss: 0.578187\n",
      "[27]\tvalid_0's binary_logloss: 0.57684\n",
      "[28]\tvalid_0's binary_logloss: 0.575715\n",
      "[29]\tvalid_0's binary_logloss: 0.574616\n",
      "[30]\tvalid_0's binary_logloss: 0.573677\n",
      "[31]\tvalid_0's binary_logloss: 0.572654\n",
      "[32]\tvalid_0's binary_logloss: 0.571662\n",
      "[33]\tvalid_0's binary_logloss: 0.570824\n",
      "[34]\tvalid_0's binary_logloss: 0.570194\n",
      "[35]\tvalid_0's binary_logloss: 0.569345\n",
      "[36]\tvalid_0's binary_logloss: 0.568581\n",
      "[37]\tvalid_0's binary_logloss: 0.568105\n",
      "[38]\tvalid_0's binary_logloss: 0.567412\n",
      "[39]\tvalid_0's binary_logloss: 0.56672\n",
      "[40]\tvalid_0's binary_logloss: 0.566248\n",
      "[41]\tvalid_0's binary_logloss: 0.565651\n",
      "[42]\tvalid_0's binary_logloss: 0.565044\n",
      "[43]\tvalid_0's binary_logloss: 0.564372\n",
      "[44]\tvalid_0's binary_logloss: 0.563953\n",
      "[45]\tvalid_0's binary_logloss: 0.563272\n",
      "[46]\tvalid_0's binary_logloss: 0.562686\n",
      "[47]\tvalid_0's binary_logloss: 0.562192\n",
      "[48]\tvalid_0's binary_logloss: 0.561844\n",
      "[49]\tvalid_0's binary_logloss: 0.561402\n",
      "[50]\tvalid_0's binary_logloss: 0.560893\n",
      "[51]\tvalid_0's binary_logloss: 0.560529\n",
      "[52]\tvalid_0's binary_logloss: 0.560336\n",
      "[53]\tvalid_0's binary_logloss: 0.560105\n",
      "[54]\tvalid_0's binary_logloss: 0.559906\n",
      "[55]\tvalid_0's binary_logloss: 0.559639\n",
      "[56]\tvalid_0's binary_logloss: 0.559329\n",
      "[57]\tvalid_0's binary_logloss: 0.55916\n",
      "[58]\tvalid_0's binary_logloss: 0.559074\n",
      "[59]\tvalid_0's binary_logloss: 0.558944\n",
      "[60]\tvalid_0's binary_logloss: 0.558737\n",
      "[61]\tvalid_0's binary_logloss: 0.558601\n",
      "[62]\tvalid_0's binary_logloss: 0.558483\n",
      "[63]\tvalid_0's binary_logloss: 0.558475\n",
      "[64]\tvalid_0's binary_logloss: 0.558286\n",
      "[65]\tvalid_0's binary_logloss: 0.558186\n",
      "[66]\tvalid_0's binary_logloss: 0.557987\n",
      "[67]\tvalid_0's binary_logloss: 0.557897\n",
      "[68]\tvalid_0's binary_logloss: 0.557789\n",
      "[69]\tvalid_0's binary_logloss: 0.557648\n",
      "[70]\tvalid_0's binary_logloss: 0.557558\n",
      "[71]\tvalid_0's binary_logloss: 0.557392\n",
      "[72]\tvalid_0's binary_logloss: 0.557329\n",
      "[73]\tvalid_0's binary_logloss: 0.557169\n",
      "[74]\tvalid_0's binary_logloss: 0.557186\n",
      "[75]\tvalid_0's binary_logloss: 0.557098\n",
      "[76]\tvalid_0's binary_logloss: 0.556894\n",
      "[77]\tvalid_0's binary_logloss: 0.556744\n",
      "[78]\tvalid_0's binary_logloss: 0.556574\n",
      "[79]\tvalid_0's binary_logloss: 0.556346\n",
      "[80]\tvalid_0's binary_logloss: 0.556225\n",
      "[81]\tvalid_0's binary_logloss: 0.556099\n",
      "[82]\tvalid_0's binary_logloss: 0.556023\n",
      "[83]\tvalid_0's binary_logloss: 0.556072\n",
      "[84]\tvalid_0's binary_logloss: 0.556013\n",
      "[85]\tvalid_0's binary_logloss: 0.555945\n",
      "[86]\tvalid_0's binary_logloss: 0.555867\n",
      "[87]\tvalid_0's binary_logloss: 0.55579\n",
      "[88]\tvalid_0's binary_logloss: 0.555755\n",
      "[89]\tvalid_0's binary_logloss: 0.555701\n",
      "[90]\tvalid_0's binary_logloss: 0.55564\n",
      "[91]\tvalid_0's binary_logloss: 0.555554\n",
      "[92]\tvalid_0's binary_logloss: 0.555566\n",
      "[93]\tvalid_0's binary_logloss: 0.555541\n",
      "[94]\tvalid_0's binary_logloss: 0.555501\n",
      "[95]\tvalid_0's binary_logloss: 0.555364\n",
      "[96]\tvalid_0's binary_logloss: 0.55536\n",
      "[97]\tvalid_0's binary_logloss: 0.555286\n",
      "[98]\tvalid_0's binary_logloss: 0.555292\n",
      "[99]\tvalid_0's binary_logloss: 0.555139\n",
      "[100]\tvalid_0's binary_logloss: 0.555112\n",
      "[101]\tvalid_0's binary_logloss: 0.555098\n",
      "[102]\tvalid_0's binary_logloss: 0.555115\n",
      "[103]\tvalid_0's binary_logloss: 0.555103\n",
      "[104]\tvalid_0's binary_logloss: 0.555039\n",
      "[105]\tvalid_0's binary_logloss: 0.554918\n",
      "[106]\tvalid_0's binary_logloss: 0.554885\n",
      "[107]\tvalid_0's binary_logloss: 0.55486\n",
      "[108]\tvalid_0's binary_logloss: 0.554842\n",
      "[109]\tvalid_0's binary_logloss: 0.554866\n",
      "[110]\tvalid_0's binary_logloss: 0.554975\n",
      "[111]\tvalid_0's binary_logloss: 0.554948\n",
      "[112]\tvalid_0's binary_logloss: 0.554873\n",
      "[113]\tvalid_0's binary_logloss: 0.554962\n",
      "[114]\tvalid_0's binary_logloss: 0.555095\n",
      "[115]\tvalid_0's binary_logloss: 0.555139\n",
      "[116]\tvalid_0's binary_logloss: 0.555106\n",
      "[117]\tvalid_0's binary_logloss: 0.555157\n",
      "[118]\tvalid_0's binary_logloss: 0.554973\n",
      "[119]\tvalid_0's binary_logloss: 0.554879\n",
      "[120]\tvalid_0's binary_logloss: 0.554868\n",
      "[121]\tvalid_0's binary_logloss: 0.554877\n",
      "[122]\tvalid_0's binary_logloss: 0.554901\n",
      "[123]\tvalid_0's binary_logloss: 0.554958\n",
      "[124]\tvalid_0's binary_logloss: 0.554932\n",
      "[125]\tvalid_0's binary_logloss: 0.555022\n",
      "[126]\tvalid_0's binary_logloss: 0.555007\n",
      "[127]\tvalid_0's binary_logloss: 0.554994\n",
      "[128]\tvalid_0's binary_logloss: 0.555033\n",
      "[129]\tvalid_0's binary_logloss: 0.555094\n",
      "[130]\tvalid_0's binary_logloss: 0.555086\n",
      "[131]\tvalid_0's binary_logloss: 0.555098\n",
      "[132]\tvalid_0's binary_logloss: 0.554925\n",
      "[133]\tvalid_0's binary_logloss: 0.55497\n",
      "[134]\tvalid_0's binary_logloss: 0.554998\n",
      "[135]\tvalid_0's binary_logloss: 0.554917\n",
      "[136]\tvalid_0's binary_logloss: 0.554866\n",
      "[137]\tvalid_0's binary_logloss: 0.555036\n",
      "[138]\tvalid_0's binary_logloss: 0.55501\n",
      "[139]\tvalid_0's binary_logloss: 0.554949\n",
      "[140]\tvalid_0's binary_logloss: 0.554955\n",
      "[141]\tvalid_0's binary_logloss: 0.554903\n",
      "[142]\tvalid_0's binary_logloss: 0.554897\n",
      "[143]\tvalid_0's binary_logloss: 0.555095\n",
      "[144]\tvalid_0's binary_logloss: 0.55507\n",
      "[145]\tvalid_0's binary_logloss: 0.555123\n",
      "[146]\tvalid_0's binary_logloss: 0.55504\n",
      "[147]\tvalid_0's binary_logloss: 0.555099\n",
      "[148]\tvalid_0's binary_logloss: 0.555097\n",
      "[149]\tvalid_0's binary_logloss: 0.555123\n",
      "[150]\tvalid_0's binary_logloss: 0.55521\n",
      "[151]\tvalid_0's binary_logloss: 0.555185\n",
      "[152]\tvalid_0's binary_logloss: 0.555238\n",
      "[153]\tvalid_0's binary_logloss: 0.55524\n",
      "[154]\tvalid_0's binary_logloss: 0.555259\n",
      "[155]\tvalid_0's binary_logloss: 0.555321\n",
      "[156]\tvalid_0's binary_logloss: 0.555337\n",
      "[157]\tvalid_0's binary_logloss: 0.555227\n",
      "[158]\tvalid_0's binary_logloss: 0.555124\n",
      "[159]\tvalid_0's binary_logloss: 0.555172\n",
      "[160]\tvalid_0's binary_logloss: 0.555152\n",
      "[161]\tvalid_0's binary_logloss: 0.555192\n",
      "[162]\tvalid_0's binary_logloss: 0.555176\n",
      "[163]\tvalid_0's binary_logloss: 0.555174\n",
      "[164]\tvalid_0's binary_logloss: 0.555198\n",
      "[165]\tvalid_0's binary_logloss: 0.555278\n",
      "[166]\tvalid_0's binary_logloss: 0.55529\n",
      "[167]\tvalid_0's binary_logloss: 0.555359\n",
      "[168]\tvalid_0's binary_logloss: 0.555411\n",
      "[169]\tvalid_0's binary_logloss: 0.555423\n",
      "[170]\tvalid_0's binary_logloss: 0.55545\n",
      "[171]\tvalid_0's binary_logloss: 0.555287\n",
      "[172]\tvalid_0's binary_logloss: 0.555235\n",
      "[173]\tvalid_0's binary_logloss: 0.555163\n",
      "[174]\tvalid_0's binary_logloss: 0.555102\n",
      "[175]\tvalid_0's binary_logloss: 0.555116\n",
      "[176]\tvalid_0's binary_logloss: 0.555139\n",
      "[177]\tvalid_0's binary_logloss: 0.555235\n",
      "[178]\tvalid_0's binary_logloss: 0.555268\n",
      "[179]\tvalid_0's binary_logloss: 0.555294\n",
      "[180]\tvalid_0's binary_logloss: 0.55528\n",
      "[181]\tvalid_0's binary_logloss: 0.55527\n",
      "[182]\tvalid_0's binary_logloss: 0.555144\n",
      "[183]\tvalid_0's binary_logloss: 0.555197\n",
      "[184]\tvalid_0's binary_logloss: 0.55529\n",
      "[185]\tvalid_0's binary_logloss: 0.55531\n",
      "[186]\tvalid_0's binary_logloss: 0.555389\n",
      "[187]\tvalid_0's binary_logloss: 0.555385\n",
      "[188]\tvalid_0's binary_logloss: 0.555376\n",
      "[189]\tvalid_0's binary_logloss: 0.555322\n",
      "[190]\tvalid_0's binary_logloss: 0.55535\n",
      "[191]\tvalid_0's binary_logloss: 0.555304\n",
      "[192]\tvalid_0's binary_logloss: 0.555342\n",
      "[193]\tvalid_0's binary_logloss: 0.555316\n",
      "[194]\tvalid_0's binary_logloss: 0.5553\n",
      "[195]\tvalid_0's binary_logloss: 0.555309\n",
      "[196]\tvalid_0's binary_logloss: 0.555236\n",
      "[197]\tvalid_0's binary_logloss: 0.555245\n",
      "[198]\tvalid_0's binary_logloss: 0.555218\n",
      "[199]\tvalid_0's binary_logloss: 0.555246\n",
      "[200]\tvalid_0's binary_logloss: 0.555296\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.554842\n"
     ]
    }
   ],
   "source": [
    "final_lgbm.fit(X_train_over, y_train_over, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set= evals, verbose=True)\n",
    "stack_pred = final_lgbm.predict(X_test)\n",
    "stack_pred_proba = final_lgbm.predict_proba(X_test)[:,1]\n",
    "stack_pred_proba_c1= stack_pred_proba.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba48b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_curve_plot(y_test, stack_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96fd12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n",
      "오차행렬\n",
      "[[1883 2101]\n",
      " [ 282 3019]]\n",
      "정확도: 0.6729, 정밀도: 0.5896, 재현율: 0.9146,    F1: 0.7170, AUC: 0.7734\n",
      "0.35\n",
      "오차행렬\n",
      "[[1909 2075]\n",
      " [ 294 3007]]\n",
      "정확도: 0.6748, 정밀도: 0.5917, 재현율: 0.9109,    F1: 0.7174, AUC: 0.7734\n",
      "0.36\n",
      "오차행렬\n",
      "[[1935 2049]\n",
      " [ 309 2992]]\n",
      "정확도: 0.6763, 정밀도: 0.5935, 재현율: 0.9064,    F1: 0.7173, AUC: 0.7734\n",
      "0.37\n",
      "오차행렬\n",
      "[[1969 2015]\n",
      " [ 321 2980]]\n",
      "정확도: 0.6793, 정밀도: 0.5966, 재현율: 0.9028,    F1: 0.7184, AUC: 0.7734\n",
      "0.38\n",
      "오차행렬\n",
      "[[1992 1992]\n",
      " [ 332 2969]]\n",
      "정확도: 0.6810, 정밀도: 0.5985, 재현율: 0.8994,    F1: 0.7187, AUC: 0.7734\n",
      "0.39\n",
      "오차행렬\n",
      "[[2016 1968]\n",
      " [ 348 2953]]\n",
      "정확도: 0.6821, 정밀도: 0.6001, 재현율: 0.8946,    F1: 0.7183, AUC: 0.7734\n",
      "0.4\n",
      "오차행렬\n",
      "[[2050 1934]\n",
      " [ 363 2938]]\n",
      "정확도: 0.6847, 정밀도: 0.6030, 재현율: 0.8900,    F1: 0.7190, AUC: 0.7734\n",
      "0.41\n",
      "오차행렬\n",
      "[[2080 1904]\n",
      " [ 375 2926]]\n",
      "정확도: 0.6872, 정밀도: 0.6058, 재현율: 0.8864,    F1: 0.7197, AUC: 0.7734\n",
      "0.42\n",
      "오차행렬\n",
      "[[2113 1871]\n",
      " [ 395 2906]]\n",
      "정확도: 0.6889, 정밀도: 0.6083, 재현율: 0.8803,    F1: 0.7195, AUC: 0.7734\n",
      "0.43\n",
      "오차행렬\n",
      "[[2140 1844]\n",
      " [ 420 2881]]\n",
      "정확도: 0.6892, 정밀도: 0.6097, 재현율: 0.8728,    F1: 0.7179, AUC: 0.7734\n",
      "0.44\n",
      "오차행렬\n",
      "[[2185 1799]\n",
      " [ 452 2849]]\n",
      "정확도: 0.6910, 정밀도: 0.6130, 재현율: 0.8631,    F1: 0.7168, AUC: 0.7734\n",
      "0.45\n",
      "오차행렬\n",
      "[[2227 1757]\n",
      " [ 482 2819]]\n",
      "정확도: 0.6927, 정밀도: 0.6160, 재현율: 0.8540,    F1: 0.7158, AUC: 0.7734\n",
      "0.46\n",
      "오차행렬\n",
      "[[2269 1715]\n",
      " [ 509 2792]]\n",
      "정확도: 0.6947, 정밀도: 0.6195, 재현율: 0.8458,    F1: 0.7152, AUC: 0.7734\n",
      "0.47\n",
      "오차행렬\n",
      "[[2305 1679]\n",
      " [ 546 2755]]\n",
      "정확도: 0.6946, 정밀도: 0.6213, 재현율: 0.8346,    F1: 0.7123, AUC: 0.7734\n",
      "0.48\n",
      "오차행렬\n",
      "[[2350 1634]\n",
      " [ 577 2724]]\n",
      "정확도: 0.6965, 정밀도: 0.6251, 재현율: 0.8252,    F1: 0.7113, AUC: 0.7734\n",
      "0.49\n",
      "오차행렬\n",
      "[[2388 1596]\n",
      " [ 618 2683]]\n",
      "정확도: 0.6961, 정밀도: 0.6270, 재현율: 0.8128,    F1: 0.7079, AUC: 0.7734\n",
      "0.5\n",
      "오차행렬\n",
      "[[2451 1533]\n",
      " [ 669 2632]]\n",
      "정확도: 0.6977, 정밀도: 0.6319, 재현율: 0.7973,    F1: 0.7051, AUC: 0.7734\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49,0.5]\n",
    "get_eval_by_threshold(y_test, stack_pred_proba, stack_pred_proba_c1, thresholds)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7f71b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold = 0.41)\n",
    "lgbm_pred_th_04 = binarizer.fit_transform(stack_pred_proba_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6200d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 F1: 0.7051\n",
      "최종 메타 모델의 임계값 조정 F1: 0.7197\n"
     ]
    }
   ],
   "source": [
    "print('최종 메타 모델의 F1: {0:.4f}'.format(f1_score(y_test, stack_pred)))\n",
    "print('최종 메타 모델의 임계값 조정 F1: {0:.4f}'.format(f1_score(y_test, lgbm_pred_th_04)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128739a",
   "metadata": {},
   "source": [
    "test 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea97d541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stack_pred = final_lgbm.predict(test_df)\n",
    "test_pred_proba_ = final_lgbm.predict_proba(test_df)[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold = 0.41)\n",
    "\n",
    "test_stack_pred_04 = binarizer.fit_transform(test_pred_proba_)\n",
    "test_stack_pred_04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab68d3",
   "metadata": {},
   "source": [
    "결과 Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bbbc2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.274813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.299183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.633454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>0.579983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>0.746963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>0.417862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>0.102875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>0.555384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_prob\n",
       "0      0.453706\n",
       "1      0.765781\n",
       "2      0.274813\n",
       "3      0.299183\n",
       "4      0.633454\n",
       "...         ...\n",
       "9102   0.579983\n",
       "9103   0.746963\n",
       "9104   0.417862\n",
       "9105   0.102875\n",
       "9106   0.555384\n",
       "\n",
       "[9107 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ['pred']\n",
    "pred_result = pd.DataFrame(test_stack_pred_04, columns=pred)\n",
    "pred_result = pred_result.astype('int')\n",
    "\n",
    "pred_prob = ['pred_prob']\n",
    "pred_proba_result = pd.DataFrame(final_lgbm.predict_proba(test_df)[:,1], columns=pred_prob)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d3f1161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38741</td>\n",
       "      <td>0.453706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43904</td>\n",
       "      <td>0.765781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41036</td>\n",
       "      <td>0.274813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6939</td>\n",
       "      <td>0.299183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14682</td>\n",
       "      <td>0.633454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>28225</td>\n",
       "      <td>0.579983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>5610</td>\n",
       "      <td>0.746963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>41745</td>\n",
       "      <td>0.417862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>24818</td>\n",
       "      <td>0.102875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>33355</td>\n",
       "      <td>0.555384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  pred_prob  pred\n",
       "0     38741   0.453706     1\n",
       "1     43904   0.765781     1\n",
       "2     41036   0.274813     0\n",
       "3      6939   0.299183     0\n",
       "4     14682   0.633454     1\n",
       "...     ...        ...   ...\n",
       "9102  28225   0.579983     1\n",
       "9103   5610   0.746963     1\n",
       "9104  41745   0.417862     1\n",
       "9105  24818   0.102875     0\n",
       "9106  33355   0.555384     1\n",
       "\n",
       "[9107 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list = {}\n",
    "test_result = pd.DataFrame(result_list)\n",
    "test_result['index'] = test_raw['index']\n",
    "test_result['pred_prob'] = pred_proba_result['pred_prob']\n",
    "test_result['pred'] = pred_result['pred']\n",
    "\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e624336",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv('test_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "276b038f",
   "metadata": {},
   "source": [
    "# 파라미터 최적화\n",
    "\n",
    "모델 구현 전 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ae92d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'num_i...</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>6</td>\n",
       "      <td>0.717214</td>\n",
       "      <td>0.715143</td>\n",
       "      <td>0.705521</td>\n",
       "      <td>0.719314</td>\n",
       "      <td>0.758725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'num_i...</td>\n",
       "      <td>0.721133</td>\n",
       "      <td>19</td>\n",
       "      <td>0.715572</td>\n",
       "      <td>0.712076</td>\n",
       "      <td>0.700461</td>\n",
       "      <td>0.716414</td>\n",
       "      <td>0.761143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'num_i...</td>\n",
       "      <td>0.719110</td>\n",
       "      <td>33</td>\n",
       "      <td>0.713847</td>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.696770</td>\n",
       "      <td>0.716560</td>\n",
       "      <td>0.760266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'num_i...</td>\n",
       "      <td>0.717784</td>\n",
       "      <td>47</td>\n",
       "      <td>0.711516</td>\n",
       "      <td>0.708685</td>\n",
       "      <td>0.692956</td>\n",
       "      <td>0.716338</td>\n",
       "      <td>0.759427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 1, 'num_i...</td>\n",
       "      <td>0.716224</td>\n",
       "      <td>70</td>\n",
       "      <td>0.710068</td>\n",
       "      <td>0.706293</td>\n",
       "      <td>0.692528</td>\n",
       "      <td>0.713062</td>\n",
       "      <td>0.759169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>81</td>\n",
       "      <td>0.702857</td>\n",
       "      <td>0.697811</td>\n",
       "      <td>0.690017</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>0.781233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.710805</td>\n",
       "      <td>156</td>\n",
       "      <td>0.701540</td>\n",
       "      <td>0.694466</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>0.692296</td>\n",
       "      <td>0.786271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.706218</td>\n",
       "      <td>223</td>\n",
       "      <td>0.696984</td>\n",
       "      <td>0.683624</td>\n",
       "      <td>0.671368</td>\n",
       "      <td>0.685171</td>\n",
       "      <td>0.793945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>263</td>\n",
       "      <td>0.688626</td>\n",
       "      <td>0.678046</td>\n",
       "      <td>0.668445</td>\n",
       "      <td>0.683560</td>\n",
       "      <td>0.796135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.702478</td>\n",
       "      <td>269</td>\n",
       "      <td>0.687751</td>\n",
       "      <td>0.676154</td>\n",
       "      <td>0.669296</td>\n",
       "      <td>0.680664</td>\n",
       "      <td>0.798526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "0    {'learning_rate': 0.05, 'max_depth': 1, 'num_i...         0.723183   \n",
       "1    {'learning_rate': 0.05, 'max_depth': 1, 'num_i...         0.721133   \n",
       "2    {'learning_rate': 0.05, 'max_depth': 1, 'num_i...         0.719110   \n",
       "3    {'learning_rate': 0.05, 'max_depth': 1, 'num_i...         0.717784   \n",
       "4    {'learning_rate': 0.05, 'max_depth': 1, 'num_i...         0.716224   \n",
       "..                                                 ...              ...   \n",
       "295  {'learning_rate': 0.1, 'max_depth': 10, 'num_i...         0.715582   \n",
       "296  {'learning_rate': 0.1, 'max_depth': 10, 'num_i...         0.710805   \n",
       "297  {'learning_rate': 0.1, 'max_depth': 10, 'num_i...         0.706218   \n",
       "298  {'learning_rate': 0.1, 'max_depth': 10, 'num_i...         0.702962   \n",
       "299  {'learning_rate': 0.1, 'max_depth': 10, 'num_i...         0.702478   \n",
       "\n",
       "     rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                  6           0.717214           0.715143           0.705521   \n",
       "1                 19           0.715572           0.712076           0.700461   \n",
       "2                 33           0.713847           0.708108           0.696770   \n",
       "3                 47           0.711516           0.708685           0.692956   \n",
       "4                 70           0.710068           0.706293           0.692528   \n",
       "..               ...                ...                ...                ...   \n",
       "295               81           0.702857           0.697811           0.690017   \n",
       "296              156           0.701540           0.694466           0.679451   \n",
       "297              223           0.696984           0.683624           0.671368   \n",
       "298              263           0.688626           0.678046           0.668445   \n",
       "299              269           0.687751           0.676154           0.669296   \n",
       "\n",
       "     split3_test_score  split4_test_score  \n",
       "0             0.719314           0.758725  \n",
       "1             0.716414           0.761143  \n",
       "2             0.716560           0.760266  \n",
       "3             0.716338           0.759427  \n",
       "4             0.713062           0.759169  \n",
       "..                 ...                ...  \n",
       "295           0.705991           0.781233  \n",
       "296           0.692296           0.786271  \n",
       "297           0.685171           0.793945  \n",
       "298           0.683560           0.796135  \n",
       "299           0.680664           0.798526  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lgbm\n",
    "lgbm_parameters = {'learning_rate':[0.05,0.06,0.07,0.08,0.09,0.1], 'num_iterations':[200, 400, 600, 800, 1000],'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "grid_lgbm_clf = GridSearchCV(lgbm_clf, param_grid=lgbm_parameters, scoring='f1', cv=5, refit= True)\n",
    "grid_lgbm_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_lgbm_clf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'learning_rate': 0.05, 'max_depth': 9, 'num_iterations': 200}\n",
      "GridSearchCV 최고 f1:0.7247\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_lgbm_clf.best_params_)\n",
    "print('GridSearchCV 최고 f1:{0:.4f}'.format(grid_lgbm_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d82a5c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10}</td>\n",
       "      <td>0.735858</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731265</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.735844</td>\n",
       "      <td>0.750851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "      <td>0.724802</td>\n",
       "      <td>5</td>\n",
       "      <td>0.721178</td>\n",
       "      <td>0.715431</td>\n",
       "      <td>0.709336</td>\n",
       "      <td>0.726350</td>\n",
       "      <td>0.751715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
       "      <td>0.720934</td>\n",
       "      <td>9</td>\n",
       "      <td>0.716900</td>\n",
       "      <td>0.716674</td>\n",
       "      <td>0.704954</td>\n",
       "      <td>0.719698</td>\n",
       "      <td>0.746446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n",
       "      <td>0.719285</td>\n",
       "      <td>13</td>\n",
       "      <td>0.715588</td>\n",
       "      <td>0.714265</td>\n",
       "      <td>0.701775</td>\n",
       "      <td>0.718452</td>\n",
       "      <td>0.746344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 400}</td>\n",
       "      <td>0.717030</td>\n",
       "      <td>20</td>\n",
       "      <td>0.714223</td>\n",
       "      <td>0.709475</td>\n",
       "      <td>0.697327</td>\n",
       "      <td>0.716852</td>\n",
       "      <td>0.747271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 600}</td>\n",
       "      <td>0.715332</td>\n",
       "      <td>25</td>\n",
       "      <td>0.712228</td>\n",
       "      <td>0.707743</td>\n",
       "      <td>0.694528</td>\n",
       "      <td>0.715805</td>\n",
       "      <td>0.746357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 10}</td>\n",
       "      <td>0.733622</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731265</td>\n",
       "      <td>0.725960</td>\n",
       "      <td>0.725678</td>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.750851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 50}</td>\n",
       "      <td>0.720252</td>\n",
       "      <td>12</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.716183</td>\n",
       "      <td>0.704040</td>\n",
       "      <td>0.717620</td>\n",
       "      <td>0.745109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 100}</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>14</td>\n",
       "      <td>0.715074</td>\n",
       "      <td>0.714476</td>\n",
       "      <td>0.704582</td>\n",
       "      <td>0.715758</td>\n",
       "      <td>0.746406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 200}</td>\n",
       "      <td>0.716294</td>\n",
       "      <td>23</td>\n",
       "      <td>0.712232</td>\n",
       "      <td>0.709339</td>\n",
       "      <td>0.697716</td>\n",
       "      <td>0.714392</td>\n",
       "      <td>0.747792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 400}</td>\n",
       "      <td>0.713194</td>\n",
       "      <td>32</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.705346</td>\n",
       "      <td>0.692911</td>\n",
       "      <td>0.711158</td>\n",
       "      <td>0.747997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'learning_rate': 0.2, 'n_estimators': 600}</td>\n",
       "      <td>0.711822</td>\n",
       "      <td>37</td>\n",
       "      <td>0.708755</td>\n",
       "      <td>0.703230</td>\n",
       "      <td>0.689519</td>\n",
       "      <td>0.710108</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 10}</td>\n",
       "      <td>0.732078</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727518</td>\n",
       "      <td>0.726082</td>\n",
       "      <td>0.723092</td>\n",
       "      <td>0.731819</td>\n",
       "      <td>0.751878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 50}</td>\n",
       "      <td>0.720558</td>\n",
       "      <td>11</td>\n",
       "      <td>0.716568</td>\n",
       "      <td>0.714139</td>\n",
       "      <td>0.704492</td>\n",
       "      <td>0.719591</td>\n",
       "      <td>0.747999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 100}</td>\n",
       "      <td>0.717745</td>\n",
       "      <td>18</td>\n",
       "      <td>0.714764</td>\n",
       "      <td>0.709822</td>\n",
       "      <td>0.699046</td>\n",
       "      <td>0.717395</td>\n",
       "      <td>0.747697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 200}</td>\n",
       "      <td>0.714911</td>\n",
       "      <td>28</td>\n",
       "      <td>0.711386</td>\n",
       "      <td>0.706486</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.715398</td>\n",
       "      <td>0.747972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 400}</td>\n",
       "      <td>0.712280</td>\n",
       "      <td>34</td>\n",
       "      <td>0.708309</td>\n",
       "      <td>0.704307</td>\n",
       "      <td>0.689487</td>\n",
       "      <td>0.710419</td>\n",
       "      <td>0.748876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'learning_rate': 0.3, 'n_estimators': 600}</td>\n",
       "      <td>0.709689</td>\n",
       "      <td>41</td>\n",
       "      <td>0.706619</td>\n",
       "      <td>0.702843</td>\n",
       "      <td>0.684323</td>\n",
       "      <td>0.707903</td>\n",
       "      <td>0.746757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 10}</td>\n",
       "      <td>0.728615</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720625</td>\n",
       "      <td>0.721615</td>\n",
       "      <td>0.718316</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.751878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 50}</td>\n",
       "      <td>0.722007</td>\n",
       "      <td>7</td>\n",
       "      <td>0.717986</td>\n",
       "      <td>0.717573</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.718016</td>\n",
       "      <td>0.747845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 100}</td>\n",
       "      <td>0.720586</td>\n",
       "      <td>10</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.714603</td>\n",
       "      <td>0.704151</td>\n",
       "      <td>0.720297</td>\n",
       "      <td>0.747829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 200}</td>\n",
       "      <td>0.716556</td>\n",
       "      <td>21</td>\n",
       "      <td>0.713781</td>\n",
       "      <td>0.709397</td>\n",
       "      <td>0.697876</td>\n",
       "      <td>0.714393</td>\n",
       "      <td>0.747333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 400}</td>\n",
       "      <td>0.712826</td>\n",
       "      <td>33</td>\n",
       "      <td>0.707843</td>\n",
       "      <td>0.708276</td>\n",
       "      <td>0.690964</td>\n",
       "      <td>0.710467</td>\n",
       "      <td>0.746580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'learning_rate': 0.4, 'n_estimators': 600}</td>\n",
       "      <td>0.709969</td>\n",
       "      <td>40</td>\n",
       "      <td>0.705425</td>\n",
       "      <td>0.702810</td>\n",
       "      <td>0.688845</td>\n",
       "      <td>0.706507</td>\n",
       "      <td>0.746260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 10}</td>\n",
       "      <td>0.714548</td>\n",
       "      <td>30</td>\n",
       "      <td>0.719038</td>\n",
       "      <td>0.702759</td>\n",
       "      <td>0.689872</td>\n",
       "      <td>0.709126</td>\n",
       "      <td>0.751943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>0.717238</td>\n",
       "      <td>19</td>\n",
       "      <td>0.714556</td>\n",
       "      <td>0.708671</td>\n",
       "      <td>0.697820</td>\n",
       "      <td>0.715833</td>\n",
       "      <td>0.749309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.714771</td>\n",
       "      <td>29</td>\n",
       "      <td>0.711320</td>\n",
       "      <td>0.707804</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>0.748256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>0.712231</td>\n",
       "      <td>35</td>\n",
       "      <td>0.710272</td>\n",
       "      <td>0.702316</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.710801</td>\n",
       "      <td>0.748602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 400}</td>\n",
       "      <td>0.708406</td>\n",
       "      <td>44</td>\n",
       "      <td>0.706253</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.684936</td>\n",
       "      <td>0.702777</td>\n",
       "      <td>0.746164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 600}</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>46</td>\n",
       "      <td>0.701193</td>\n",
       "      <td>0.702147</td>\n",
       "      <td>0.683911</td>\n",
       "      <td>0.699770</td>\n",
       "      <td>0.745104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 10}</td>\n",
       "      <td>0.718825</td>\n",
       "      <td>15</td>\n",
       "      <td>0.715581</td>\n",
       "      <td>0.712242</td>\n",
       "      <td>0.703752</td>\n",
       "      <td>0.719146</td>\n",
       "      <td>0.743405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 50}</td>\n",
       "      <td>0.716443</td>\n",
       "      <td>22</td>\n",
       "      <td>0.712141</td>\n",
       "      <td>0.709745</td>\n",
       "      <td>0.699392</td>\n",
       "      <td>0.717715</td>\n",
       "      <td>0.743220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 100}</td>\n",
       "      <td>0.715303</td>\n",
       "      <td>26</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.707446</td>\n",
       "      <td>0.696109</td>\n",
       "      <td>0.715034</td>\n",
       "      <td>0.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 200}</td>\n",
       "      <td>0.711173</td>\n",
       "      <td>39</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.703574</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.710789</td>\n",
       "      <td>0.743076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 400}</td>\n",
       "      <td>0.708739</td>\n",
       "      <td>43</td>\n",
       "      <td>0.705936</td>\n",
       "      <td>0.701012</td>\n",
       "      <td>0.684919</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.744212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'learning_rate': 0.6, 'n_estimators': 600}</td>\n",
       "      <td>0.704338</td>\n",
       "      <td>49</td>\n",
       "      <td>0.697936</td>\n",
       "      <td>0.697861</td>\n",
       "      <td>0.681468</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.744212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 10}</td>\n",
       "      <td>0.721686</td>\n",
       "      <td>8</td>\n",
       "      <td>0.714367</td>\n",
       "      <td>0.713894</td>\n",
       "      <td>0.707088</td>\n",
       "      <td>0.727169</td>\n",
       "      <td>0.745913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 50}</td>\n",
       "      <td>0.717863</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>0.707044</td>\n",
       "      <td>0.700741</td>\n",
       "      <td>0.717684</td>\n",
       "      <td>0.746444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 100}</td>\n",
       "      <td>0.715602</td>\n",
       "      <td>24</td>\n",
       "      <td>0.712813</td>\n",
       "      <td>0.709455</td>\n",
       "      <td>0.697396</td>\n",
       "      <td>0.713383</td>\n",
       "      <td>0.744960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 200}</td>\n",
       "      <td>0.711354</td>\n",
       "      <td>38</td>\n",
       "      <td>0.707025</td>\n",
       "      <td>0.705078</td>\n",
       "      <td>0.688146</td>\n",
       "      <td>0.710756</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 400}</td>\n",
       "      <td>0.706370</td>\n",
       "      <td>47</td>\n",
       "      <td>0.701071</td>\n",
       "      <td>0.702040</td>\n",
       "      <td>0.683047</td>\n",
       "      <td>0.699725</td>\n",
       "      <td>0.745969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'learning_rate': 0.7, 'n_estimators': 600}</td>\n",
       "      <td>0.702335</td>\n",
       "      <td>51</td>\n",
       "      <td>0.692985</td>\n",
       "      <td>0.696778</td>\n",
       "      <td>0.678433</td>\n",
       "      <td>0.698510</td>\n",
       "      <td>0.744970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 10}</td>\n",
       "      <td>0.723784</td>\n",
       "      <td>6</td>\n",
       "      <td>0.722532</td>\n",
       "      <td>0.721933</td>\n",
       "      <td>0.717942</td>\n",
       "      <td>0.710592</td>\n",
       "      <td>0.745923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 50}</td>\n",
       "      <td>0.717792</td>\n",
       "      <td>17</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>0.710444</td>\n",
       "      <td>0.698102</td>\n",
       "      <td>0.716316</td>\n",
       "      <td>0.746315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 100}</td>\n",
       "      <td>0.712186</td>\n",
       "      <td>36</td>\n",
       "      <td>0.707610</td>\n",
       "      <td>0.707247</td>\n",
       "      <td>0.691609</td>\n",
       "      <td>0.710661</td>\n",
       "      <td>0.743804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 200}</td>\n",
       "      <td>0.707737</td>\n",
       "      <td>45</td>\n",
       "      <td>0.700978</td>\n",
       "      <td>0.702653</td>\n",
       "      <td>0.685381</td>\n",
       "      <td>0.706474</td>\n",
       "      <td>0.743197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 400}</td>\n",
       "      <td>0.704217</td>\n",
       "      <td>50</td>\n",
       "      <td>0.697292</td>\n",
       "      <td>0.697194</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.700061</td>\n",
       "      <td>0.743612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'learning_rate': 0.8, 'n_estimators': 600}</td>\n",
       "      <td>0.700019</td>\n",
       "      <td>52</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.695128</td>\n",
       "      <td>0.672486</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.744484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 10}</td>\n",
       "      <td>0.714066</td>\n",
       "      <td>31</td>\n",
       "      <td>0.710224</td>\n",
       "      <td>0.702646</td>\n",
       "      <td>0.701857</td>\n",
       "      <td>0.708835</td>\n",
       "      <td>0.746767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 50}</td>\n",
       "      <td>0.715016</td>\n",
       "      <td>27</td>\n",
       "      <td>0.711909</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.693748</td>\n",
       "      <td>0.720305</td>\n",
       "      <td>0.741423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 100}</td>\n",
       "      <td>0.709277</td>\n",
       "      <td>42</td>\n",
       "      <td>0.704847</td>\n",
       "      <td>0.698452</td>\n",
       "      <td>0.688107</td>\n",
       "      <td>0.710427</td>\n",
       "      <td>0.744554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 200}</td>\n",
       "      <td>0.705032</td>\n",
       "      <td>48</td>\n",
       "      <td>0.699805</td>\n",
       "      <td>0.697086</td>\n",
       "      <td>0.685504</td>\n",
       "      <td>0.702454</td>\n",
       "      <td>0.740310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 400}</td>\n",
       "      <td>0.698928</td>\n",
       "      <td>53</td>\n",
       "      <td>0.691887</td>\n",
       "      <td>0.689044</td>\n",
       "      <td>0.675043</td>\n",
       "      <td>0.696802</td>\n",
       "      <td>0.741862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>{'learning_rate': 0.9, 'n_estimators': 600}</td>\n",
       "      <td>0.698289</td>\n",
       "      <td>54</td>\n",
       "      <td>0.694542</td>\n",
       "      <td>0.689827</td>\n",
       "      <td>0.670414</td>\n",
       "      <td>0.694294</td>\n",
       "      <td>0.742368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         params  mean_test_score  \\\n",
       "0    {'learning_rate': 0.1, 'n_estimators': 10}         0.735858   \n",
       "1    {'learning_rate': 0.1, 'n_estimators': 50}         0.724802   \n",
       "2   {'learning_rate': 0.1, 'n_estimators': 100}         0.720934   \n",
       "3   {'learning_rate': 0.1, 'n_estimators': 200}         0.719285   \n",
       "4   {'learning_rate': 0.1, 'n_estimators': 400}         0.717030   \n",
       "5   {'learning_rate': 0.1, 'n_estimators': 600}         0.715332   \n",
       "6    {'learning_rate': 0.2, 'n_estimators': 10}         0.733622   \n",
       "7    {'learning_rate': 0.2, 'n_estimators': 50}         0.720252   \n",
       "8   {'learning_rate': 0.2, 'n_estimators': 100}         0.719259   \n",
       "9   {'learning_rate': 0.2, 'n_estimators': 200}         0.716294   \n",
       "10  {'learning_rate': 0.2, 'n_estimators': 400}         0.713194   \n",
       "11  {'learning_rate': 0.2, 'n_estimators': 600}         0.711822   \n",
       "12   {'learning_rate': 0.3, 'n_estimators': 10}         0.732078   \n",
       "13   {'learning_rate': 0.3, 'n_estimators': 50}         0.720558   \n",
       "14  {'learning_rate': 0.3, 'n_estimators': 100}         0.717745   \n",
       "15  {'learning_rate': 0.3, 'n_estimators': 200}         0.714911   \n",
       "16  {'learning_rate': 0.3, 'n_estimators': 400}         0.712280   \n",
       "17  {'learning_rate': 0.3, 'n_estimators': 600}         0.709689   \n",
       "18   {'learning_rate': 0.4, 'n_estimators': 10}         0.728615   \n",
       "19   {'learning_rate': 0.4, 'n_estimators': 50}         0.722007   \n",
       "20  {'learning_rate': 0.4, 'n_estimators': 100}         0.720586   \n",
       "21  {'learning_rate': 0.4, 'n_estimators': 200}         0.716556   \n",
       "22  {'learning_rate': 0.4, 'n_estimators': 400}         0.712826   \n",
       "23  {'learning_rate': 0.4, 'n_estimators': 600}         0.709969   \n",
       "24   {'learning_rate': 0.5, 'n_estimators': 10}         0.714548   \n",
       "25   {'learning_rate': 0.5, 'n_estimators': 50}         0.717238   \n",
       "26  {'learning_rate': 0.5, 'n_estimators': 100}         0.714771   \n",
       "27  {'learning_rate': 0.5, 'n_estimators': 200}         0.712231   \n",
       "28  {'learning_rate': 0.5, 'n_estimators': 400}         0.708406   \n",
       "29  {'learning_rate': 0.5, 'n_estimators': 600}         0.706425   \n",
       "30   {'learning_rate': 0.6, 'n_estimators': 10}         0.718825   \n",
       "31   {'learning_rate': 0.6, 'n_estimators': 50}         0.716443   \n",
       "32  {'learning_rate': 0.6, 'n_estimators': 100}         0.715303   \n",
       "33  {'learning_rate': 0.6, 'n_estimators': 200}         0.711173   \n",
       "34  {'learning_rate': 0.6, 'n_estimators': 400}         0.708739   \n",
       "35  {'learning_rate': 0.6, 'n_estimators': 600}         0.704338   \n",
       "36   {'learning_rate': 0.7, 'n_estimators': 10}         0.721686   \n",
       "37   {'learning_rate': 0.7, 'n_estimators': 50}         0.717863   \n",
       "38  {'learning_rate': 0.7, 'n_estimators': 100}         0.715602   \n",
       "39  {'learning_rate': 0.7, 'n_estimators': 200}         0.711354   \n",
       "40  {'learning_rate': 0.7, 'n_estimators': 400}         0.706370   \n",
       "41  {'learning_rate': 0.7, 'n_estimators': 600}         0.702335   \n",
       "42   {'learning_rate': 0.8, 'n_estimators': 10}         0.723784   \n",
       "43   {'learning_rate': 0.8, 'n_estimators': 50}         0.717792   \n",
       "44  {'learning_rate': 0.8, 'n_estimators': 100}         0.712186   \n",
       "45  {'learning_rate': 0.8, 'n_estimators': 200}         0.707737   \n",
       "46  {'learning_rate': 0.8, 'n_estimators': 400}         0.704217   \n",
       "47  {'learning_rate': 0.8, 'n_estimators': 600}         0.700019   \n",
       "48   {'learning_rate': 0.9, 'n_estimators': 10}         0.714066   \n",
       "49   {'learning_rate': 0.9, 'n_estimators': 50}         0.715016   \n",
       "50  {'learning_rate': 0.9, 'n_estimators': 100}         0.709277   \n",
       "51  {'learning_rate': 0.9, 'n_estimators': 200}         0.705032   \n",
       "52  {'learning_rate': 0.9, 'n_estimators': 400}         0.698928   \n",
       "53  {'learning_rate': 0.9, 'n_estimators': 600}         0.698289   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                 1           0.731265           0.728507           0.732824   \n",
       "1                 5           0.721178           0.715431           0.709336   \n",
       "2                 9           0.716900           0.716674           0.704954   \n",
       "3                13           0.715588           0.714265           0.701775   \n",
       "4                20           0.714223           0.709475           0.697327   \n",
       "5                25           0.712228           0.707743           0.694528   \n",
       "6                 2           0.731265           0.725960           0.725678   \n",
       "7                12           0.718310           0.716183           0.704040   \n",
       "8                14           0.715074           0.714476           0.704582   \n",
       "9                23           0.712232           0.709339           0.697716   \n",
       "10               32           0.708556           0.705346           0.692911   \n",
       "11               37           0.708755           0.703230           0.689519   \n",
       "12                3           0.727518           0.726082           0.723092   \n",
       "13               11           0.716568           0.714139           0.704492   \n",
       "14               18           0.714764           0.709822           0.699046   \n",
       "15               28           0.711386           0.706486           0.693313   \n",
       "16               34           0.708309           0.704307           0.689487   \n",
       "17               41           0.706619           0.702843           0.684323   \n",
       "18                4           0.720625           0.721615           0.718316   \n",
       "19                7           0.717986           0.717573           0.708613   \n",
       "20               10           0.716049           0.714603           0.704151   \n",
       "21               21           0.713781           0.709397           0.697876   \n",
       "22               33           0.707843           0.708276           0.690964   \n",
       "23               40           0.705425           0.702810           0.688845   \n",
       "24               30           0.719038           0.702759           0.689872   \n",
       "25               19           0.714556           0.708671           0.697820   \n",
       "26               29           0.711320           0.707804           0.692875   \n",
       "27               35           0.710272           0.702316           0.689162   \n",
       "28               44           0.706253           0.701900           0.684936   \n",
       "29               46           0.701193           0.702147           0.683911   \n",
       "30               15           0.715581           0.712242           0.703752   \n",
       "31               22           0.712141           0.709745           0.699392   \n",
       "32               26           0.713633           0.707446           0.696109   \n",
       "33               39           0.707692           0.703574           0.690733   \n",
       "34               43           0.705936           0.701012           0.684919   \n",
       "35               49           0.697936           0.697861           0.681468   \n",
       "36                8           0.714367           0.713894           0.707088   \n",
       "37               16           0.717404           0.707044           0.700741   \n",
       "38               24           0.712813           0.709455           0.697396   \n",
       "39               38           0.707025           0.705078           0.688146   \n",
       "40               47           0.701071           0.702040           0.683047   \n",
       "41               51           0.692985           0.696778           0.678433   \n",
       "42                6           0.722532           0.721933           0.717942   \n",
       "43               17           0.717785           0.710444           0.698102   \n",
       "44               36           0.707610           0.707247           0.691609   \n",
       "45               45           0.700978           0.702653           0.685381   \n",
       "46               50           0.697292           0.697194           0.682927   \n",
       "47               52           0.691098           0.695128           0.672486   \n",
       "48               31           0.710224           0.702646           0.701857   \n",
       "49               27           0.711909           0.707692           0.693748   \n",
       "50               42           0.704847           0.698452           0.688107   \n",
       "51               48           0.699805           0.697086           0.685504   \n",
       "52               53           0.691887           0.689044           0.675043   \n",
       "53               54           0.694542           0.689827           0.670414   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.735844           0.750851  \n",
       "1            0.726350           0.751715  \n",
       "2            0.719698           0.746446  \n",
       "3            0.718452           0.746344  \n",
       "4            0.716852           0.747271  \n",
       "5            0.715805           0.746357  \n",
       "6            0.734354           0.750851  \n",
       "7            0.717620           0.745109  \n",
       "8            0.715758           0.746406  \n",
       "9            0.714392           0.747792  \n",
       "10           0.711158           0.747997  \n",
       "11           0.710108           0.747500  \n",
       "12           0.731819           0.751878  \n",
       "13           0.719591           0.747999  \n",
       "14           0.717395           0.747697  \n",
       "15           0.715398           0.747972  \n",
       "16           0.710419           0.748876  \n",
       "17           0.707903           0.746757  \n",
       "18           0.730641           0.751878  \n",
       "19           0.718016           0.747845  \n",
       "20           0.720297           0.747829  \n",
       "21           0.714393           0.747333  \n",
       "22           0.710467           0.746580  \n",
       "23           0.706507           0.746260  \n",
       "24           0.709126           0.751943  \n",
       "25           0.715833           0.749309  \n",
       "26           0.713600           0.748256  \n",
       "27           0.710801           0.748602  \n",
       "28           0.702777           0.746164  \n",
       "29           0.699770           0.745104  \n",
       "30           0.719146           0.743405  \n",
       "31           0.717715           0.743220  \n",
       "32           0.715034           0.744292  \n",
       "33           0.710789           0.743076  \n",
       "34           0.707617           0.744212  \n",
       "35           0.700215           0.744212  \n",
       "36           0.727169           0.745913  \n",
       "37           0.717684           0.746444  \n",
       "38           0.713383           0.744960  \n",
       "39           0.710756           0.745763  \n",
       "40           0.699725           0.745969  \n",
       "41           0.698510           0.744970  \n",
       "42           0.710592           0.745923  \n",
       "43           0.716316           0.746315  \n",
       "44           0.710661           0.743804  \n",
       "45           0.706474           0.743197  \n",
       "46           0.700061           0.743612  \n",
       "47           0.696900           0.744484  \n",
       "48           0.708835           0.746767  \n",
       "49           0.720305           0.741423  \n",
       "50           0.710427           0.744554  \n",
       "51           0.702454           0.740310  \n",
       "52           0.696802           0.741862  \n",
       "53           0.694294           0.742368  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ada\n",
    "ada_parameters = {'n_estimators':[10,50,100,200,400,600], 'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
    "grid_ada_clf = GridSearchCV(ada_clf, param_grid=ada_parameters, scoring='f1', cv=5, refit= True)\n",
    "grid_ada_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_ada_clf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58fbe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "GridSearchCV 최고 f1:0.7359\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_ada_clf.best_params_)\n",
    "print('GridSearchCV 최고 f1:{0:.4f}'.format(grid_ada_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70686b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 6}</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 8}</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 10}</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.676374</td>\n",
       "      <td>0.669245</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.676374</td>\n",
       "      <td>0.669245</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 6}</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.676374</td>\n",
       "      <td>0.669245</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 8}</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.676374</td>\n",
       "      <td>0.669245</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 10}</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>46</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.676374</td>\n",
       "      <td>0.669245</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.755601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.719594</td>\n",
       "      <td>31</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.721573</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.726657</td>\n",
       "      <td>0.717112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 4}</td>\n",
       "      <td>0.719594</td>\n",
       "      <td>31</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.721573</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.726657</td>\n",
       "      <td>0.717112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 6}</td>\n",
       "      <td>0.719594</td>\n",
       "      <td>31</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.721573</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.726657</td>\n",
       "      <td>0.717112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 8}</td>\n",
       "      <td>0.719594</td>\n",
       "      <td>31</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.721573</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.726657</td>\n",
       "      <td>0.717112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 10}</td>\n",
       "      <td>0.719594</td>\n",
       "      <td>31</td>\n",
       "      <td>0.718903</td>\n",
       "      <td>0.721573</td>\n",
       "      <td>0.713723</td>\n",
       "      <td>0.726657</td>\n",
       "      <td>0.717112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 4}</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 6}</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 8}</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 10}</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>16</td>\n",
       "      <td>0.717490</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>11</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>0.747402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 4}</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>11</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>0.747402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 6}</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>11</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>0.747402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 8}</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>11</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>0.747402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>11</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.729308</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>0.732446</td>\n",
       "      <td>0.747402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2}</td>\n",
       "      <td>0.716454</td>\n",
       "      <td>38</td>\n",
       "      <td>0.712676</td>\n",
       "      <td>0.729462</td>\n",
       "      <td>0.698380</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.739505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 4}</td>\n",
       "      <td>0.716454</td>\n",
       "      <td>38</td>\n",
       "      <td>0.712676</td>\n",
       "      <td>0.729462</td>\n",
       "      <td>0.698380</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.739505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 6}</td>\n",
       "      <td>0.716516</td>\n",
       "      <td>36</td>\n",
       "      <td>0.712778</td>\n",
       "      <td>0.729462</td>\n",
       "      <td>0.698587</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.739505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 8}</td>\n",
       "      <td>0.716480</td>\n",
       "      <td>37</td>\n",
       "      <td>0.712778</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>0.698587</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.739505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 10}</td>\n",
       "      <td>0.716444</td>\n",
       "      <td>40</td>\n",
       "      <td>0.712778</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>0.698587</td>\n",
       "      <td>0.702246</td>\n",
       "      <td>0.739327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 2}</td>\n",
       "      <td>0.735304</td>\n",
       "      <td>8</td>\n",
       "      <td>0.730991</td>\n",
       "      <td>0.728340</td>\n",
       "      <td>0.714593</td>\n",
       "      <td>0.745093</td>\n",
       "      <td>0.757503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 4}</td>\n",
       "      <td>0.735276</td>\n",
       "      <td>10</td>\n",
       "      <td>0.730991</td>\n",
       "      <td>0.728340</td>\n",
       "      <td>0.714593</td>\n",
       "      <td>0.745093</td>\n",
       "      <td>0.757365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 6}</td>\n",
       "      <td>0.735328</td>\n",
       "      <td>7</td>\n",
       "      <td>0.731065</td>\n",
       "      <td>0.728340</td>\n",
       "      <td>0.714777</td>\n",
       "      <td>0.745093</td>\n",
       "      <td>0.757365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 8}</td>\n",
       "      <td>0.735348</td>\n",
       "      <td>6</td>\n",
       "      <td>0.731065</td>\n",
       "      <td>0.728442</td>\n",
       "      <td>0.714777</td>\n",
       "      <td>0.745093</td>\n",
       "      <td>0.757365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 10}</td>\n",
       "      <td>0.735287</td>\n",
       "      <td>9</td>\n",
       "      <td>0.730991</td>\n",
       "      <td>0.728442</td>\n",
       "      <td>0.714777</td>\n",
       "      <td>0.745093</td>\n",
       "      <td>0.757133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2}</td>\n",
       "      <td>0.720499</td>\n",
       "      <td>28</td>\n",
       "      <td>0.720246</td>\n",
       "      <td>0.724103</td>\n",
       "      <td>0.695120</td>\n",
       "      <td>0.712959</td>\n",
       "      <td>0.750069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 4}</td>\n",
       "      <td>0.720606</td>\n",
       "      <td>26</td>\n",
       "      <td>0.720638</td>\n",
       "      <td>0.724103</td>\n",
       "      <td>0.695120</td>\n",
       "      <td>0.713409</td>\n",
       "      <td>0.749759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 6}</td>\n",
       "      <td>0.720450</td>\n",
       "      <td>29</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.724103</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.713409</td>\n",
       "      <td>0.749656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 8}</td>\n",
       "      <td>0.720407</td>\n",
       "      <td>30</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.723921</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.713409</td>\n",
       "      <td>0.749621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 10}</td>\n",
       "      <td>0.720513</td>\n",
       "      <td>27</td>\n",
       "      <td>0.720414</td>\n",
       "      <td>0.723921</td>\n",
       "      <td>0.694822</td>\n",
       "      <td>0.713409</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2}</td>\n",
       "      <td>0.722021</td>\n",
       "      <td>23</td>\n",
       "      <td>0.717210</td>\n",
       "      <td>0.709536</td>\n",
       "      <td>0.706686</td>\n",
       "      <td>0.730844</td>\n",
       "      <td>0.745828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 4}</td>\n",
       "      <td>0.722029</td>\n",
       "      <td>22</td>\n",
       "      <td>0.716827</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.706601</td>\n",
       "      <td>0.730615</td>\n",
       "      <td>0.746273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 6}</td>\n",
       "      <td>0.721833</td>\n",
       "      <td>25</td>\n",
       "      <td>0.716587</td>\n",
       "      <td>0.709744</td>\n",
       "      <td>0.706771</td>\n",
       "      <td>0.730440</td>\n",
       "      <td>0.745624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 8}</td>\n",
       "      <td>0.721880</td>\n",
       "      <td>24</td>\n",
       "      <td>0.716587</td>\n",
       "      <td>0.709895</td>\n",
       "      <td>0.706378</td>\n",
       "      <td>0.730642</td>\n",
       "      <td>0.745897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 10}</td>\n",
       "      <td>0.722086</td>\n",
       "      <td>21</td>\n",
       "      <td>0.717130</td>\n",
       "      <td>0.709933</td>\n",
       "      <td>0.706481</td>\n",
       "      <td>0.730817</td>\n",
       "      <td>0.746069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "      <td>0.715924</td>\n",
       "      <td>41</td>\n",
       "      <td>0.714609</td>\n",
       "      <td>0.712066</td>\n",
       "      <td>0.689316</td>\n",
       "      <td>0.717592</td>\n",
       "      <td>0.746038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 4}</td>\n",
       "      <td>0.715779</td>\n",
       "      <td>44</td>\n",
       "      <td>0.714427</td>\n",
       "      <td>0.712396</td>\n",
       "      <td>0.688988</td>\n",
       "      <td>0.717730</td>\n",
       "      <td>0.745352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 6}</td>\n",
       "      <td>0.715611</td>\n",
       "      <td>45</td>\n",
       "      <td>0.714367</td>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.718094</td>\n",
       "      <td>0.746006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 8}</td>\n",
       "      <td>0.715796</td>\n",
       "      <td>43</td>\n",
       "      <td>0.714811</td>\n",
       "      <td>0.712647</td>\n",
       "      <td>0.687723</td>\n",
       "      <td>0.717796</td>\n",
       "      <td>0.746006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10}</td>\n",
       "      <td>0.715842</td>\n",
       "      <td>42</td>\n",
       "      <td>0.714468</td>\n",
       "      <td>0.712851</td>\n",
       "      <td>0.688998</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>0.745482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  mean_test_score  \\\n",
       "0     {'max_depth': 1, 'min_samples_split': 2}         0.739478   \n",
       "1     {'max_depth': 1, 'min_samples_split': 4}         0.739478   \n",
       "2     {'max_depth': 1, 'min_samples_split': 6}         0.739478   \n",
       "3     {'max_depth': 1, 'min_samples_split': 8}         0.739478   \n",
       "4    {'max_depth': 1, 'min_samples_split': 10}         0.739478   \n",
       "5     {'max_depth': 2, 'min_samples_split': 2}         0.690559   \n",
       "6     {'max_depth': 2, 'min_samples_split': 4}         0.690559   \n",
       "7     {'max_depth': 2, 'min_samples_split': 6}         0.690559   \n",
       "8     {'max_depth': 2, 'min_samples_split': 8}         0.690559   \n",
       "9    {'max_depth': 2, 'min_samples_split': 10}         0.690559   \n",
       "10    {'max_depth': 3, 'min_samples_split': 2}         0.719594   \n",
       "11    {'max_depth': 3, 'min_samples_split': 4}         0.719594   \n",
       "12    {'max_depth': 3, 'min_samples_split': 6}         0.719594   \n",
       "13    {'max_depth': 3, 'min_samples_split': 8}         0.719594   \n",
       "14   {'max_depth': 3, 'min_samples_split': 10}         0.719594   \n",
       "15    {'max_depth': 4, 'min_samples_split': 2}         0.727807   \n",
       "16    {'max_depth': 4, 'min_samples_split': 4}         0.727807   \n",
       "17    {'max_depth': 4, 'min_samples_split': 6}         0.727807   \n",
       "18    {'max_depth': 4, 'min_samples_split': 8}         0.727807   \n",
       "19   {'max_depth': 4, 'min_samples_split': 10}         0.727807   \n",
       "20    {'max_depth': 5, 'min_samples_split': 2}         0.731237   \n",
       "21    {'max_depth': 5, 'min_samples_split': 4}         0.731237   \n",
       "22    {'max_depth': 5, 'min_samples_split': 6}         0.731237   \n",
       "23    {'max_depth': 5, 'min_samples_split': 8}         0.731237   \n",
       "24   {'max_depth': 5, 'min_samples_split': 10}         0.731237   \n",
       "25    {'max_depth': 6, 'min_samples_split': 2}         0.716454   \n",
       "26    {'max_depth': 6, 'min_samples_split': 4}         0.716454   \n",
       "27    {'max_depth': 6, 'min_samples_split': 6}         0.716516   \n",
       "28    {'max_depth': 6, 'min_samples_split': 8}         0.716480   \n",
       "29   {'max_depth': 6, 'min_samples_split': 10}         0.716444   \n",
       "30    {'max_depth': 7, 'min_samples_split': 2}         0.735304   \n",
       "31    {'max_depth': 7, 'min_samples_split': 4}         0.735276   \n",
       "32    {'max_depth': 7, 'min_samples_split': 6}         0.735328   \n",
       "33    {'max_depth': 7, 'min_samples_split': 8}         0.735348   \n",
       "34   {'max_depth': 7, 'min_samples_split': 10}         0.735287   \n",
       "35    {'max_depth': 8, 'min_samples_split': 2}         0.720499   \n",
       "36    {'max_depth': 8, 'min_samples_split': 4}         0.720606   \n",
       "37    {'max_depth': 8, 'min_samples_split': 6}         0.720450   \n",
       "38    {'max_depth': 8, 'min_samples_split': 8}         0.720407   \n",
       "39   {'max_depth': 8, 'min_samples_split': 10}         0.720513   \n",
       "40    {'max_depth': 9, 'min_samples_split': 2}         0.722021   \n",
       "41    {'max_depth': 9, 'min_samples_split': 4}         0.722029   \n",
       "42    {'max_depth': 9, 'min_samples_split': 6}         0.721833   \n",
       "43    {'max_depth': 9, 'min_samples_split': 8}         0.721880   \n",
       "44   {'max_depth': 9, 'min_samples_split': 10}         0.722086   \n",
       "45   {'max_depth': 10, 'min_samples_split': 2}         0.715924   \n",
       "46   {'max_depth': 10, 'min_samples_split': 4}         0.715779   \n",
       "47   {'max_depth': 10, 'min_samples_split': 6}         0.715611   \n",
       "48   {'max_depth': 10, 'min_samples_split': 8}         0.715796   \n",
       "49  {'max_depth': 10, 'min_samples_split': 10}         0.715842   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                 1           0.734472           0.735105           0.732824   \n",
       "1                 1           0.734472           0.735105           0.732824   \n",
       "2                 1           0.734472           0.735105           0.732824   \n",
       "3                 1           0.734472           0.735105           0.732824   \n",
       "4                 1           0.734472           0.735105           0.732824   \n",
       "5                46           0.676724           0.676374           0.669245   \n",
       "6                46           0.676724           0.676374           0.669245   \n",
       "7                46           0.676724           0.676374           0.669245   \n",
       "8                46           0.676724           0.676374           0.669245   \n",
       "9                46           0.676724           0.676374           0.669245   \n",
       "10               31           0.718903           0.721573           0.713723   \n",
       "11               31           0.718903           0.721573           0.713723   \n",
       "12               31           0.718903           0.721573           0.713723   \n",
       "13               31           0.718903           0.721573           0.713723   \n",
       "14               31           0.718903           0.721573           0.713723   \n",
       "15               16           0.717490           0.716046           0.725642   \n",
       "16               16           0.717490           0.716046           0.725642   \n",
       "17               16           0.717490           0.716046           0.725642   \n",
       "18               16           0.717490           0.716046           0.725642   \n",
       "19               16           0.717490           0.716046           0.725642   \n",
       "20               11           0.723553           0.729308           0.723476   \n",
       "21               11           0.723553           0.729308           0.723476   \n",
       "22               11           0.723553           0.729308           0.723476   \n",
       "23               11           0.723553           0.729308           0.723476   \n",
       "24               11           0.723553           0.729308           0.723476   \n",
       "25               38           0.712676           0.729462           0.698380   \n",
       "26               38           0.712676           0.729462           0.698380   \n",
       "27               36           0.712778           0.729462           0.698587   \n",
       "28               37           0.712778           0.729282           0.698587   \n",
       "29               40           0.712778           0.729282           0.698587   \n",
       "30                8           0.730991           0.728340           0.714593   \n",
       "31               10           0.730991           0.728340           0.714593   \n",
       "32                7           0.731065           0.728340           0.714777   \n",
       "33                6           0.731065           0.728442           0.714777   \n",
       "34                9           0.730991           0.728442           0.714777   \n",
       "35               28           0.720246           0.724103           0.695120   \n",
       "36               26           0.720638           0.724103           0.695120   \n",
       "37               29           0.720078           0.724103           0.695004   \n",
       "38               30           0.720078           0.723921           0.695004   \n",
       "39               27           0.720414           0.723921           0.694822   \n",
       "40               23           0.717210           0.709536           0.706686   \n",
       "41               22           0.716827           0.709829           0.706601   \n",
       "42               25           0.716587           0.709744           0.706771   \n",
       "43               24           0.716587           0.709895           0.706378   \n",
       "44               21           0.717130           0.709933           0.706481   \n",
       "45               41           0.714609           0.712066           0.689316   \n",
       "46               44           0.714427           0.712396           0.688988   \n",
       "47               45           0.714367           0.711874           0.687714   \n",
       "48               43           0.714811           0.712647           0.687723   \n",
       "49               42           0.714468           0.712851           0.688998   \n",
       "\n",
       "    split3_test_score  split4_test_score  \n",
       "0            0.739384           0.755601  \n",
       "1            0.739384           0.755601  \n",
       "2            0.739384           0.755601  \n",
       "3            0.739384           0.755601  \n",
       "4            0.739384           0.755601  \n",
       "5            0.674849           0.755601  \n",
       "6            0.674849           0.755601  \n",
       "7            0.674849           0.755601  \n",
       "8            0.674849           0.755601  \n",
       "9            0.674849           0.755601  \n",
       "10           0.726657           0.717112  \n",
       "11           0.726657           0.717112  \n",
       "12           0.726657           0.717112  \n",
       "13           0.726657           0.717112  \n",
       "14           0.726657           0.717112  \n",
       "15           0.716948           0.762908  \n",
       "16           0.716948           0.762908  \n",
       "17           0.716948           0.762908  \n",
       "18           0.716948           0.762908  \n",
       "19           0.716948           0.762908  \n",
       "20           0.732446           0.747402  \n",
       "21           0.732446           0.747402  \n",
       "22           0.732446           0.747402  \n",
       "23           0.732446           0.747402  \n",
       "24           0.732446           0.747402  \n",
       "25           0.702246           0.739505  \n",
       "26           0.702246           0.739505  \n",
       "27           0.702246           0.739505  \n",
       "28           0.702246           0.739505  \n",
       "29           0.702246           0.739327  \n",
       "30           0.745093           0.757503  \n",
       "31           0.745093           0.757365  \n",
       "32           0.745093           0.757365  \n",
       "33           0.745093           0.757365  \n",
       "34           0.745093           0.757133  \n",
       "35           0.712959           0.750069  \n",
       "36           0.713409           0.749759  \n",
       "37           0.713409           0.749656  \n",
       "38           0.713409           0.749621  \n",
       "39           0.713409           0.750000  \n",
       "40           0.730844           0.745828  \n",
       "41           0.730615           0.746273  \n",
       "42           0.730440           0.745624  \n",
       "43           0.730642           0.745897  \n",
       "44           0.730817           0.746069  \n",
       "45           0.717592           0.746038  \n",
       "46           0.717730           0.745352  \n",
       "47           0.718094           0.746006  \n",
       "48           0.717796           0.746006  \n",
       "49           0.717410           0.745482  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dt\n",
    "dt_parameters = {'max_depth':[1,2,3,4,5,6,7,8,9,10], 'min_samples_split':[2,4,6,8,10]}\n",
    "grid_dt_clf = GridSearchCV(dt_clf, param_grid=dt_parameters, scoring='f1', cv=5, refit= True)\n",
    "grid_dt_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dt_clf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d99dafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 1, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 f1:0.7395\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dt_clf.best_params_)\n",
    "print('GridSearchCV 최고 f1:{0:.4f}'.format(grid_dt_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68efd5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.604164</td>\n",
       "      <td>296</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.604971</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.599029</td>\n",
       "      <td>0.619819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.677761</td>\n",
       "      <td>266</td>\n",
       "      <td>0.674408</td>\n",
       "      <td>0.669784</td>\n",
       "      <td>0.659432</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>0.709177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.667402</td>\n",
       "      <td>281</td>\n",
       "      <td>0.665598</td>\n",
       "      <td>0.659158</td>\n",
       "      <td>0.648394</td>\n",
       "      <td>0.663644</td>\n",
       "      <td>0.700217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.674562</td>\n",
       "      <td>276</td>\n",
       "      <td>0.673424</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.653593</td>\n",
       "      <td>0.672444</td>\n",
       "      <td>0.703890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.689387</td>\n",
       "      <td>247</td>\n",
       "      <td>0.688304</td>\n",
       "      <td>0.681470</td>\n",
       "      <td>0.674028</td>\n",
       "      <td>0.685634</td>\n",
       "      <td>0.717501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.716182</td>\n",
       "      <td>21</td>\n",
       "      <td>0.707321</td>\n",
       "      <td>0.702916</td>\n",
       "      <td>0.694613</td>\n",
       "      <td>0.713276</td>\n",
       "      <td>0.762783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.717264</td>\n",
       "      <td>9</td>\n",
       "      <td>0.709534</td>\n",
       "      <td>0.708490</td>\n",
       "      <td>0.692659</td>\n",
       "      <td>0.710923</td>\n",
       "      <td>0.764714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>12</td>\n",
       "      <td>0.708834</td>\n",
       "      <td>0.705634</td>\n",
       "      <td>0.690371</td>\n",
       "      <td>0.713660</td>\n",
       "      <td>0.767506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.718358</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708970</td>\n",
       "      <td>0.705136</td>\n",
       "      <td>0.692624</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>0.770859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.718296</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709218</td>\n",
       "      <td>0.705223</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.713468</td>\n",
       "      <td>0.771872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "0    {'max_depth': 1, 'min_samples_split': 2, 'n_es...         0.604164   \n",
       "1    {'max_depth': 1, 'min_samples_split': 2, 'n_es...         0.677761   \n",
       "2    {'max_depth': 1, 'min_samples_split': 2, 'n_es...         0.667402   \n",
       "3    {'max_depth': 1, 'min_samples_split': 2, 'n_es...         0.674562   \n",
       "4    {'max_depth': 1, 'min_samples_split': 2, 'n_es...         0.689387   \n",
       "..                                                 ...              ...   \n",
       "295  {'max_depth': 10, 'min_samples_split': 10, 'n_...         0.716182   \n",
       "296  {'max_depth': 10, 'min_samples_split': 10, 'n_...         0.717264   \n",
       "297  {'max_depth': 10, 'min_samples_split': 10, 'n_...         0.717201   \n",
       "298  {'max_depth': 10, 'min_samples_split': 10, 'n_...         0.718358   \n",
       "299  {'max_depth': 10, 'min_samples_split': 10, 'n_...         0.718296   \n",
       "\n",
       "     rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                296           0.607595           0.604971           0.589404   \n",
       "1                266           0.674408           0.669784           0.659432   \n",
       "2                281           0.665598           0.659158           0.648394   \n",
       "3                276           0.673424           0.669457           0.653593   \n",
       "4                247           0.688304           0.681470           0.674028   \n",
       "..               ...                ...                ...                ...   \n",
       "295               21           0.707321           0.702916           0.694613   \n",
       "296                9           0.709534           0.708490           0.692659   \n",
       "297               12           0.708834           0.705634           0.690371   \n",
       "298                2           0.708970           0.705136           0.692624   \n",
       "299                3           0.709218           0.705223           0.691700   \n",
       "\n",
       "     split3_test_score  split4_test_score  \n",
       "0             0.599029           0.619819  \n",
       "1             0.676003           0.709177  \n",
       "2             0.663644           0.700217  \n",
       "3             0.672444           0.703890  \n",
       "4             0.685634           0.717501  \n",
       "..                 ...                ...  \n",
       "295           0.713276           0.762783  \n",
       "296           0.710923           0.764714  \n",
       "297           0.713660           0.767506  \n",
       "298           0.714200           0.770859  \n",
       "299           0.713468           0.771872  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf\n",
    "rf_parameters = {'n_estimators':[10,50,100,200,400,600], 'max_depth':[1,2,3,4,5,6,7,8,9,10], 'min_samples_split':[2,4,6,8,10]}\n",
    "grid_rf_clf = GridSearchCV(rf_clf, param_grid=rf_parameters, scoring='f1', cv=5, refit= True)\n",
    "grid_rf_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_rf_clf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e24669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "GridSearchCV 최고 f1:0.7185\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_rf_clf.best_params_)\n",
    "print('GridSearchCV 최고 f1:{0:.4f}'.format(grid_rf_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adb8ebb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'num_it...</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.746788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'num_it...</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.746788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'num_it...</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.746788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'num_it...</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.746788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'num_it...</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717765</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.718686</td>\n",
       "      <td>0.746788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>{'learning_rate': 0.9, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.666819</td>\n",
       "      <td>361</td>\n",
       "      <td>0.636045</td>\n",
       "      <td>0.638880</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.642673</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>{'learning_rate': 0.9, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.666819</td>\n",
       "      <td>361</td>\n",
       "      <td>0.636045</td>\n",
       "      <td>0.638880</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.642673</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>{'learning_rate': 0.9, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.666819</td>\n",
       "      <td>361</td>\n",
       "      <td>0.636045</td>\n",
       "      <td>0.638880</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.642673</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>{'learning_rate': 0.9, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.666819</td>\n",
       "      <td>361</td>\n",
       "      <td>0.636045</td>\n",
       "      <td>0.638880</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.642673</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>{'learning_rate': 0.9, 'max_depth': 10, 'num_i...</td>\n",
       "      <td>0.666819</td>\n",
       "      <td>361</td>\n",
       "      <td>0.636045</td>\n",
       "      <td>0.638880</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.642673</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "0    {'learning_rate': 0.1, 'max_depth': 1, 'num_it...         0.720825   \n",
       "1    {'learning_rate': 0.1, 'max_depth': 1, 'num_it...         0.720825   \n",
       "2    {'learning_rate': 0.1, 'max_depth': 1, 'num_it...         0.720825   \n",
       "3    {'learning_rate': 0.1, 'max_depth': 1, 'num_it...         0.720825   \n",
       "4    {'learning_rate': 0.1, 'max_depth': 1, 'num_it...         0.720825   \n",
       "..                                                 ...              ...   \n",
       "445  {'learning_rate': 0.9, 'max_depth': 10, 'num_i...         0.666819   \n",
       "446  {'learning_rate': 0.9, 'max_depth': 10, 'num_i...         0.666819   \n",
       "447  {'learning_rate': 0.9, 'max_depth': 10, 'num_i...         0.666819   \n",
       "448  {'learning_rate': 0.9, 'max_depth': 10, 'num_i...         0.666819   \n",
       "449  {'learning_rate': 0.9, 'max_depth': 10, 'num_i...         0.666819   \n",
       "\n",
       "     rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                  1           0.717765           0.715709           0.705175   \n",
       "1                  1           0.717765           0.715709           0.705175   \n",
       "2                  1           0.717765           0.715709           0.705175   \n",
       "3                  1           0.717765           0.715709           0.705175   \n",
       "4                  1           0.717765           0.715709           0.705175   \n",
       "..               ...                ...                ...                ...   \n",
       "445              361           0.636045           0.638880           0.633755   \n",
       "446              361           0.636045           0.638880           0.633755   \n",
       "447              361           0.636045           0.638880           0.633755   \n",
       "448              361           0.636045           0.638880           0.633755   \n",
       "449              361           0.636045           0.638880           0.633755   \n",
       "\n",
       "     split3_test_score  split4_test_score  \n",
       "0             0.718686           0.746788  \n",
       "1             0.718686           0.746788  \n",
       "2             0.718686           0.746788  \n",
       "3             0.718686           0.746788  \n",
       "4             0.718686           0.746788  \n",
       "..                 ...                ...  \n",
       "445           0.642673           0.782741  \n",
       "446           0.642673           0.782741  \n",
       "447           0.642673           0.782741  \n",
       "448           0.642673           0.782741  \n",
       "449           0.642673           0.782741  \n",
       "\n",
       "[450 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb\n",
    "xgb_parameters = {'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9], 'num_iterations':[200, 400, 600, 800, 1000],'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "grid_xgb_clf = GridSearchCV(xgb_clf, param_grid=xgb_parameters, scoring='f1', cv=5, refit= True)\n",
    "grid_xgb_clf.fit(X_train_over, y_train_over)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_xgb_clf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e551ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 1, 'num_iterations': 200}\n",
      "GridSearchCV 최고 f1:0.7208\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_xgb_clf.best_params_)\n",
    "print('GridSearchCV 최고 f1:{0:.4f}'.format(grid_xgb_clf.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ssu] *",
   "language": "python",
   "name": "conda-env-ssu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
